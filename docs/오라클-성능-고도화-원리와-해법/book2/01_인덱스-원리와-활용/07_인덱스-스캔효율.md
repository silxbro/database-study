# 07. 인덱스 스캔효율

이전에 블록 단위 I/O 원리를 설명하면서 Random 액세스와 Sequential 액세스의 차이점을 자세히 설명하였다.

Sequential 액세스는 레코드간 논리적 또는 물리적인 순서를 따라 차례대로 읽어 나가느나 방식을 말하고, Random 액세스는 레코드간 논리적, 물리적인 순서를 따르지 않고 한 건을 읽기 위해 한 블록씩
접근(=touch)하는 방식이라고 했다. 그리고 I/O 튜닝의 핵심 원리로서 아래 두 가지 항목을 꼽았다.

- [1] Sequential 액세스의 선택도를 높인다.
- [2] Random 액세스 발생량을 줄인다.

4절에서 테이블 Random 액세스 부하 원리에 대해 설명했고, 5절과 6절에선 부하 해소 원리를 설명했는데, 이는 [2]번 항목에 해당한다.

지금부터는 [1]번 Sequential 액세스의 선택도를 높이는 방법에 대해 설명하려고 한다. 즉, 테이블을 액세스하기 전, 인덱스를 Sequential 방식으로 스캔하는 단계에서 발생하는 비효율 해소 원리를 다룬다.

- ### [Sequential 액세스 선택도]

  일반적인 의미에서의 선택도는 전체 레코드 중에서 조건절에 의해 선택되는 비율을 말한다.
  또한, 조나단 루이스는 그의 저서 Cost-Based Oracle Fundamentals에서 인덱스 액세스에 대한 비용 공식을 쉽게 설명하려고 아래 두 가지 용어를 도입하였으며, 4절에서 이미 소개한 바 있다.

  - 유효 인덱스 선택도 : 전체 인덱스 레코드 중에서 조건절을 만족하는 레코드를 찾기 위해 스캔할 것으로 예상되는 비율(%)
  - 유효 테이블 선택도 : 전체 레코드 중에서 인덱스 스캔을 완료하고서 최종적으로 테이블을 방문할 것으로 예상되는 비율(%)

  조나단 루이스가 말하는 유효 테이블 선택도가 높다면 인덱스 스캔 후 테이블 Random 액세스 비율이 높은 것이므로 앞서 선택도가 높아야 효율적이라고 한 필자의 주장과 배치된다.

  하지만 본 절에서 말하는 'Sequential 액세스 선택도'는 인덱스를 스캔한 건수 중 결과로 선택되는 비율을 말하는 것이며, 그 비율이 높아야 효율적이라는 의미는 같은 결과 건수를 내기 위해 적은 양을
  읽어야 함을 이르는 것이다.

<br/>

## (1) 비교 연산자 종류와 컬럼 순서에 따른 인덱스 레코드의 군집성
인덱스 스캔의 효율성을 설명하기에 앞서 인덱스 레코드의 특성을 한 가지 이해하고 넘어갈 필요가 있다.

테이블과 달리 인덱스 레코드는 '같은 값을 갖는' 레코드들이 항상 서로 군집해 왔다.
그런데 '같은 값을 갖는다'라고 하면 '=' 비교가 전제되므로, 만약 비교 연산자가 '=' 조건이 아닐 때는 인덱스 레코드도 서로 흩어진 상태일 수 있다.

- ### [선두 컬럼, 선행 커럶]

  생각하기에 따라 같은 용어라고 해석될 수 있지만 서로 헷갈리지 않도록 정리해 보자.
  '선두 컬럼'은 인덱스 구성상 맨 앞쪽에 있는 컬럼을 지칭할 때 사용하고, '선행 컬럼'은 상대적으로 앞쪽에 놓인 컬럼을 칭할 때 사용할 것이다. 선두 컬럼은 당연히 선행 컬럼에 포함된다.

아래와 같이 인덱스 구성 컬럼(col1, col2, col3, col4)이 모두 '=' 조건으로 비교될 때는 조건을 만족하는 레코드들이 모두 연속되게 모여 있는 것을 볼 수 있다.
```
where col1 = 1 and col2 = 'A' and col3 = '나' and col4 = 'a'
```
아래와 같이 선행 컬럼은 모두 '='이고 맨 마지막 컬럼만 범위검색 조건(부등호, between, like)일 때도 조건을 만족하는 레코드가 서로 모여 있다.
```
where col1 = 1 and col2 = 'A' and col3 = '나' and col4 >= 'a'
```
만약 맨 마지막 컬럼이 아닌 중간 컬럼이 범위검색 조건일 때는 어떻게 되는지 살펴보자.
첫 번째 예로, 아래와 같이 세 번째 컬럼 col3가 범위검색 조건인 경우는 col1부터 col3까지 세 조건만을 만족하는 인덱스 레코드는 서로 모여 있지만 col4 조건까지 만족하는 레코드는 흩어지게 된다.
```
where col1 = 1 and col2 = 'A' and col3 between '가' and '다' and col4 = 'a'
```
두 번째 예로, 아래와 같이 두 번재 컬럼 col2가 범위검색 조건인 경우는 col1부터 col2까지 두 조건만을 만족하는 인덱스 레코드는 서로 모이지만 col3와 col4 조건까지 만족하는 레코드는 흩어지게 된다.
```
where col1 = 1 and col2 <= 'B' and col3 between '가' and '다' and col4 between 'a' and 'b'
```
여기서 우리는 한 가지 규칙을 발견할 수 있다.
선행 컬럼이 모두 '=' 조건인 상태에서 첫 번째 나타나는 범위검색 조건까지만 만족하는 인덱스 레코드는 모두 연속되게 모여 있지만, 그 이하 조건까지 만족하는 레코드는 비교 연산자 종류에 상관없이 흩어진다
(우연히 모여 있을 수는 있음)는 규칙이다.

만약 아래와 같이 맨 선두 컬럼이 범위검색 조건이면 그 조건을 만족하는 레코드만 서로 모여있고, 나머지 조건까지 만족하는 레코드는 비교 연산자 종류에 상관없이 흩어지게 된다.
```
where col1 between 1 and 2 and col2 = 'A' and col3 = '나' and col4 = 'a'
```

<br/>

## (2) 인덱스 선행 컬럼이 등치(=) 조건이 아닐 때 발생하는 비효율
Sequential 액세스 효율은 선택도에 의해 결정된다. 달리 표현하면, 같은 결과 건수를 내는데 얼마나 적은 레코드를 읽느냐로 효율성을 판단할 수 있다.

인덱스 Sequential 액세스에 따른 선택도는 인덱스 컬럼이 조건절에 모두 등치(=) 조건으로 사용될 때 가장 높다.
리프 블록을 스캔하면서 읽은 레코드는 하나도 필터링되지 않고 모두 테이블 액세스로 이어지기 때문이다. 따라서 인덱스 스캔 단계에서의 비효율은 전혀 없다.

인덱스 컬럼 중 일부가 조건절에서 생략되거나 '=' 조건이 아니더라도, 그것이 뒤쪽 컬럼일 때는 비효율이 없다.
예를 들어, 인덱스가 [아파트시세코드 + 평형 + 평형타입 + 인터넷매물] 순으로 구성됐을 때 조건절이 아래와 같은 경우를 말한다.
```
where 아파트시세크도 = :a
where 아파트시세크도 = :a and 평형 = :b
where 아파트시세크도 = :a and 평형 = :b and 평형타입 = :c
where 아파트시세크도 = :a and 평형 = :b and 평형타입 between :c and :d
```

반면, 인덱스 선행 컬럼이 조건절에 누락되거나 between, 부등호, like 같은 범위검색 조건이 사용되면 인덱스를 스캔하는 단계에서 비효율이 발생한다.

예를 들어, 인덱스가 [아파트시세코드 + 평형 + 평형타입 + 인터넷매물] 순으로 구성된 상황에서 아래 SQL을 수행하는 경우를 살펴보자.
```
select 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
from   매물아파트매매
where  아파트시세코드 = 'A01011350900056'
and    평형 = '59'
and    평형타입 = 'A'
and    인터넷매물 between '1' and '2'
order by 입력일 desc
```
인터넷매물이 between 조건이지만 선행 컬럼들이 모두 '=' 조건이기 때문에 전혀 비효율 없이 조건을 만족하는 2건을 빠르게 찾았다. 비효율이 전혀 없다는 것은 2건을 찾기 위해 단 3건만 스캔했음을 의미한다.
맨 마지막 스캔은 더 이상 조건을 만족하는 레코드가 없음을 확인하기 위한 one-plus 스캔이므로 불가피하다.

인덱스 선행 컬럼이 모두 '=' 조건일 때 필요한 범위만 스캔하고 멈출 수 있는 것은, 조건을 만족하는 레코드가 모두 한데 모여 있기 때문이다.

이제 인덱스 구성을 [인터넷매물 + 아파트시세코드 + 평형 + 평형타입] 순으로 바꾸고 나서 같은 SQL을 수행해보면, 인덱스 스캔 범위가 넓어진다.

인덱스 선두 컬럼 인터넷매물에 between 연산자를 사용하면 나머지 조건을 만족하는 레코드들이 인터넷 매물 값(0, 1, 2, 3)별로 뿔뿔이 흩어져 있게 된다.
따라서 조건을 만족하지 않는 레코드까지 스캔하고서 버려야 하는 비효율이 생긴다.

- ### [선두 컬럼이 BETWEEN일 때 스캔 시작과 종료 지점]

  위 사례에서 다행히 스캔 시작점은 3번째 레코드(인터넷매물 = '1'이 시작되는 지점)가 아니라 6번째 레코드다.
  인덱스 스캔 시작점을 찾는 수직적 탐색 과정에서 [인터넷매물 = '1' and 아파트시세코드 < 'A01011350900056' and 평형타입 < 'A'] 인 레코드들은 이미 필터링되었기 때문이다.

  또한, between 조건의 종료 값 구간(인터넷매물 = '2')을 스캔할 때는 [아파트시세코드 > 'A01011350900056' or 평형 > '59' or 평형타입 > 'A']인 지점에서 스캔을 멈출 수 있다.
  따라서 스캔 종료지점은 밑에서 2번째 레코드(인터넷매물 = '3'이 시작되는 지점)가 아니라 밑에서 5번째 레코드가 된다.

<br/>

## (3) BETWEEN 조건을 IN-List로 바꾸었을 때 인덱스 스캔 효율
범위검색 컬럼이 맨 뒤로 가도록 인덱스를 [아파트시세코드 + 평형 + 평형타입 + 인터넷매물] 순으로 변경하면 좋겠지만 운영 중인 시스템에서 인덱스 구성을 바꾸기는 쉽지 않다.
이럴 때 between 조건을 아래와 같이 IN-List로 바꿔주면 가끔 큰 효과를 얻는다.
```
select 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
from   매물아파트매매
where  인터넷매물 in ('1', '2')
and    아파트시세코드 = 'A01011350900056'
and    평형 = '59'
and    평형타입 = 'A'
order by 입력일 desc
```

이때, 인덱스의 수직적 탐색이 두 번 발생하며, 이때의 실행계획은 아래(INLIST ITERATOR 오퍼레이션 주목)와 같다.
```
------------------------------------------------------------------------
| Id | Operation                      | Name          | Rows  | Bytes  |
------------------------------------------------------------------------
|  0 | SELECT STATEMENT               |               |     1 |     37 |
|  1 |   INLIST ITERATOR              |               |       |        |
|  2 |     TABLE ACCESS BY IDNEX ROWID| 매물아파트매매    |     1 |     37 |
|  3 |       INDEX RANGE SCAN         | 매물아파트매매_PK |     1 |        |
------------------------------------------------------------------------
```
인덱스를 위와 같이 두 번 탐색한다는 것은 SQL을 아래와 같이 작성한 것과 마찬가지 결과가 된다. 모든 컬럼이 '=' 조건인 것에 주목하기 바란다.
```
select 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
from   매물아파트매매
where  인터넷매물 = '1'
and    아파트시세코드 = 'A01011350900056'
and    평형 = '59'
and    평형타입 = 'A'
union all
select 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
from   매물아파트매매
where  인터넷매물 = '2'
and    아파트시세코드 = 'A01011350900056'
and    평형 = '59'
and    평형타입 = 'A'
order by 입력일 desc
```
실제로 RBO 모드에서는 인덱스 컬럼에 IN-List 조건절을 사용하면 아래와 같은 Concatenation 방식의 실행계획이 나타난다. 이는 쿼리가 내부적으로 union all 방식으로 변환되고 나서 실행됨을 의미한다.
```
------------------------------------------------------------------------
| Id | Operation                      | Name          | Rows  | Bytes  |
------------------------------------------------------------------------
|  0 | SELECT STATEMENT               |               |     2 |     74 |
|  1 |   CONCATENATIOn                |               |       |        |
|  2 |     TABLE ACCESS BY IDNEX ROWID| 매물아파트매매    |     1 |     37 |
|  3 |       INDEX UNIQUE SCAN        | 매물아파트매매_PK |     1 |        |
|  4 |     TABLE ACCESS BY IDNEX ROWID| 매물아파트매매    |     1 |     37 |
|  5 |       INDEX UNIQUE SCAN        | 매물아파트매매_PK |     1 |        |
------------------------------------------------------------------------
```
IN-List 개수만큼 union all 브랜치가 생성되고, 각 브랜치마다 모든 컬럼을 '=' 조건으로 검색하기 때문에 앞서 선두 컬럼을 between 조건으로 비교할 때와 같은 비효율이 사라진다.
참고로, 3절에서 배운 Index Skip Scan 방식으로 유도하더라도 비슷한 효율을 얻을 수 있다.

IN-List 항목 개수가 늘거나 줄 수 있다면(예를 들어, 인터넷 매물 '1'과 '2' 사이에 다른 값 추가), 아래처럼 NL 방식의 조인문이나 서브쿼리로 구현하면 된다.
물론 IN-List 값들을 코드 테이블로 관리하고 있을 때 가능한 방식이다.

```
select /*+ ordered use_nl(b) */ b.해당층, b.평당가, b.입력일
     , b.해당동, b.매물구분, b.연사용일수, b.중개업소코드
from   통합코드 a, 매물아파트매매 b
where  a.코드구분 = 'CD064'  -- 인터넷매물구분
and    a.코드 between '1' and '2'
and    b.인터넷매물 = a.코드
and    b.아파트시세코드 = 'A01011350900056'
and    b.평형 = '59'
and    b.평형타입 = 'A'
order by b.입력일 desc
```

### [between 조건을 IN-List 조건으로 바꿀 때 주의 사항]
인덱스 선두 컬럼의 between 조건을 IN-List 조건으로 바꿀 때 주의할 점은, IN-List 개수가 많지 않아야 한다는 것이다.
필요 없는 범위를 스캔하는 비효율은 사라지겠지만 인덱스 수직 탐색이 여러 번 발생하기 때문이다.
IN-List 개수가 많을 때는, between 조건 때문에 리프 블록을 추가로 스캔하는 비효율보다 IN-List 조건 때문에 브랜치 블록을 반복 탐색하는 비효율이 더 클 수 있고, 인덱스 높이(height)가 높을 때
특히 그렇다.(경우에 따라서는 인덱스 수직 탐색 과정에서의 일량도 상당하다.)

인덱스 스캔 과정에서 선택되는 레코드들이 서로 멀리 떨어져 있을 때만 유용하다는 사실도 기억하기 바란다.
between 조건인 선행 컬럼 때문에 많은 인덱스 리프 블록을 스캔하지만 거기서 선택되는 레코드는 소량일 때라야 IN-List로의 변환이 효과를 낸다.
왜냐면, 많은 레코드를 스캔하는 비효율이 있을지언정 블록 I/O 측면에서는 대개 소량에 그치는 경우가 많기 때문이다.
인덱스 리프 블록에는 테이블 블록과 달리 매우 많은(8KB 블록 기준으로 대략 수백 개) 레코드가 담긴다.

<br/>

## (4) Index Skip Scan을 이용한 비효율 해소
3절에서 Index Skip Scan을 설명하면서 언급했듯이 인덱스 선두 컬럼이 누락됐을 때뿐만 아니라 부등호, between, like 같은 범위검색 조건일 때도 Index Skip Scan이 유용하게 사용될 수 있고,
데이터 상황에 따라서는 '=' 조건 컬럼들을 인덱스 선두에 위치시킨 것에 버금가는 효과를 얻는다.

아래와 같이 월별고객별판매집계 테이블을 생성하고 직접 테스트를 통해 확인해 보자.
```
create table 월별고객별판매집계
as
select rownum 고객번호
     , '2008' || lpad(ceil(rownum/100000), 2, '0') 판매월
     , decode(mod(rownum, 12), 1, 'A', 'B') 판매구분
     , round(dbms_random.value(1000, 100000), -2) 판매금액
from dual
connect by level <= 1200000 ;
```
2008년 1월부터 12월까지 월별로 10만 개(총 120만 개) 판매데이터가 입력되도록 하였다. 판매구분 값별로는 'A'가 10만 개, 'B'가 110만 개다.
이 테이블을 이용해 아래와 같은 count 쿼리를 수행하려고 한다.
```
select count(*)
from   월별고객별판매집계 t
where  판매구분 = 'A'
and    판매월 between '200801' and '200812'
```
이 쿼리를 위해서라면 '=' 조건인 판매구분이 선두컬럼에 위치하도록 아래와 같이 인덱스를 구성하는 것이 가장 효과적이다.
```
create index 월별고객별판매집계_IDX1 on 월별고객별판매집계(판매구분, 판매월);
```
아래는 IDX1 인덱스를 사용할 때의 트레이스 결과로서, 인덱스를 스캔하면서 281개의 블록 I/O가 발생한 것을 볼 수 있다. 테이블 액세스는 전혀 발생하지 않는다.
```
Rows   Row Source Operation
------  ---------------------------------------------------------------------
     1  SORT AGGREGATE (cr=281 pr=0 pw=0 time=47753 us)
100000    INDEX RANGE SCAN 월별고객별판매집계_IDX1 (cr=281 pr=0 pw=0 time= ...)
```
이번에는 between 조건인 판매월 컬럼을 선두로 갖는 아래 인덱스를 사용하는 경우를 살펴보자.
```
create index 월별고객별판매집계_IDX2 on 월별고객별판매집계(판매월, 판매구분);
```
판매구분 = 'A'인 레코드는 2008년 1월부터 12월까지 각 판매월 앞쪽에 위치함과 동시에, 전체에서 차지하는 비중이 8.3%에 불과하기 때문에 서로 멀리 떨어지게 된다.

아래는 방금 생성한 IDX2 인덱스를 사용할 때의 트레이스 결과로서, 인덱스를 스캔하면서 3,090개의 블록 I/O가 발생한 것을 볼 수 있다.
테이블을 전혀 방문하지 않았음에도 I/O가 많이 발생한 이유는, 인덱스 선두 컬럼이 between 조건이어서 판매구분이 'B'인 레코드까지 모두 스캔하고서 버렸기 때문이다.
```
select /*+ index(t 월별고객별판매집계_IDX2) */ count(*)
from   월별고객별판매집계 t
where  판매구분 = 'A'
and    판매월 between '200801' and '200812'

Rows   Row Source Operation
------  ---------------------------------------------------------------------
     1  SORT AGGREGATE (cr=3090 pr=0 pw=0 time=206430 us)
100000    INDEX RANGE SCAN 월별고객별판매집계_IDX2 (cr=3090 pr=0 pw=0 time= ...)
```

앞서 설명한 튜닝 방식을 적용해 between 조건을 IN-List로 변환하고서 다시 실행해 보자.
```
select /*+ index(t 월별고객별판매집계_IDX2) */ count(*)
from   월별고객별판매집계 t
where  판매구분 = 'A'
and    판매월 in ( '200801', '200802', '200803', '200804', '200805', '200806'
               , '200807', '200808', '200809', '200810', '200811', '200812' )

Rows   Row Source Operation
------  ---------------------------------------------------------------------
     1  SORT AGGREGATE (cr=314 pr=0 pw=0 time=31527 us)
100000    INLIST ITERATOR (cr=314 pr=0 pw=0 time=900030 us)
100000      INDEX RANGE SCAN 월별고객별판매집계_IDX2 (cr=314 pr=0 pw=0 time= ...)
```

3,090개이던 블록 I/O 개수가 314개로 감소하였다. 인덱스 브랜치 블록을 12번 반복 탐색하는 비효율이 있긴 하지만 리프 블록을 스캔할 때의 비효율을 제거함으로써 1/10 수준으로 성능 개선을 이루었다.

마지막 시도로서, Index Skip Scan으로 유도해 보자.
```
select /*+ INDEX_SS(t 월별고객별판매집계_IDX2) */ count(*)
from   월별고객별판매집계 t
where  판매구분 = 'A'
and    판매월 between '200801' and '200812'

Rows   Row Source Operation
------  ---------------------------------------------------------------------
     1  SORT AGGREGATE (cr=300 pr=0 pw=0 time=94282 us)
100000    INDEX SKIP SCAN 월별고객별판매집계_IDX2 (cr=300 pr=0 pw=0 time=500073 us)
```
인덱스 선두 컬럼이 between 조건임에도 큰 비효율 없이 단 300 블록만 읽고 일을 마쳤다.
아래 표는 네 가지 테스트 결과를 요약한 것인데, Index Skip Scan이 IN-List보다 오히려 낫고 [판매구분 + 판매월] 순으로 구성된 IDX1 인덱스를 사용할 때와 비교해서도 별 차이가 없다.

|구분|IDX1 인덱스|Between|IN-List|Skip Scan|
|:---:|:---:|:---:|:---:|:---:|
|블록 I/O|281|3,090|314|300|

**선두 컬럼이 between이어서 나머지 검색 조건을 만족하는 데이터들이 서로 멀리 떨어져 있을 때**가, Index Skip Scan으로써 효과를 볼 수 있는 전형적인 케이스다
(불필요한 리프 블록에 대한 액세스를 Skip하고 가능성 있는 리프 블록으로 점프).

<br/>

## (5) 범위검색 조건을 남용할 때 발생하는 비효율
지금까지 between을 중심으로 설명했는데, 여기서는 like 조건을 기준으로 설명을 진행하겠다. like도 between일 때와 기본 원리는 같고, 다만 스캔 범위에 약간의 차이가 생긴다.
이에 대해서는 바로 다음 항에서 설명한다.

사용자 선택에 따라 조건절이 다양하게 바뀔 때 SQL을 간편하게 작성하려고 조건절을 모두 like로 구사하는 개발팀을 종종 보는데, 해당 컬럼이 인덱스 구성 컬럼일 때는 주의가 필요하다.

예를 들어, 회사, 지역, 상품명 등을 입력함으로써 '가입상품' 테이블에서 데이터를 조회하는 프로그램이 있다고 하자.
조회 화면에서 회사(참고로, 가입접수를 받은 회사를 의미함)는 반드시 입력해야 하지만 지역은 입력하지 않을 수도 있다. 그리고 상품명은 단어 중 일부만 입력하고도 조회 가능하도록 하는 것이 업무 요건이다.
따라서 이 프로그램은 내부적으로 아래 두 쿼리 중 하나를 선택적으로 사용할 것이다.
```
# 쿼리 1 : 회사, 지역, 상품명을 모두 입력할 때
SELECT 고객ID, 상품명, 지역, ...
FROM   가입상품
WHERE  회사 = :com
AND    지역 = :reg
AND    상품명 LIKE :prod || '%'

# 쿼리 2 : 회사, 상품명만 입력할 때
SELECT 고객ID, 상품명, 지역, ...
FROM   가입상품
WHERE  회사 = :com
AND    상품명 LIKE :prod || '%'
```
인덱스는 [회사 + 지역 + 상품명] 순으로 구성되었다고 하자.

인덱스 중간 컬럼(=지역)에 대한 조건이 누락됐을 때는 어쩔 수 없이 넓은 범위를 스캔하겠지만, 이 조건이 입력됐을 때만큼은 아주 적은 범위만 스캔하고 빠르게 결과를 출력할 수 있다.

그런데 이 프로그램을 담당한 개발자가 두 가지 상황을 모두 만족하는 하나의 SQL로 구현하려고 아래와 같이 지역 컬럼 조건에 Like 연산자를 사용하였다면 조회 성능에 어떤 영향을 미치게 될까?
```
SELECT 고객ID, 상품명, 지역, ...
FROM   가입상품
WHERE  회사 = :com
AND    지역 LIKE :reg || '%'
AND    상품명 LIKE :prod || '%'
```
인덱스 구성이 같을 때, 지역을 입력 안 한 경우는 당연히 인덱스 스캔 범위가 이전과 동일하겠지만, 지역을 입력한 경우는 인덱스 스캔 범위가 늘어날 것이다.
이처럼 코딩을 쉽게 하려고 인덱스 컬럼에 범위검색 조건을 남용하면 첫 번째 범위검색 조건에 의해 스캔 범위가 대부분 결정되며, 그 다음을 따르는 조건부터는 스캔 범위를 줄이는 데에 크게 기여하지 못하므로
성능상 불리해질 수 있다.
- 첫 번째 범위검색 조건 다음에 놓인 조건들도 스캔 범위를 줄이는 데에 약간 도움을 주기는 한다.

스캔량이 적을 때는 그 차이가 미미하지만 대량일 떄는 상당한 속도차이를 보일 수 있다. 따라서 SQL을 작성할 때 주의가 요구되며, 인덱스 컬럼에 대해 비교 연산자를 신중하게 선택해야 하는 이유다.

- ### [범위검색 조건만으로 구성된 쿼리 튜닝 사례]

  오래 전에 콜택시 관제시스템을 튜닝한 적이 있다.
  운행 중인 택시들로부터 10초마다 송신돼 온 위치정보를 데이터베이스에 저장하고 있다가 고객으로부터 콜(Call)이 오면 반경 1km 이내의 가장 가까운 택시에게 신호를 보내는 시스템이다.
  이 서비스를 위해 사용된 쿼리는 아래와 같다.

  ```
  select 위치명
  from
      (select decode(sign(b.우편번호코드-40000), 1, '', b.지역명1||' ')||
              nvl(b.지역명2, '') || ' ' || a.gis_위치명 위치명,
              sqrt(power((a.gis_위도-:승객위도)*111000,2)+
                   power((a.gis_경도-:승객경도)*88000,2)) 거리
       from   gis데이터 a, 우편번호 b
       where  a.gis_위도 between :승객위도 - 1 and :승객위도 + 1
       and    a.gis_경도 between :승객경도 - 1 and :승객경도 + 1
       and    sysdate between a.gis_시작일자 and a.gis_종료일자
       and    a.gis_지역코드 = b.우편번호코드
       order by 거리)
  where rownum<=1;
  ```

  그리고 인덱스 구성은 다음과 같다.

  ```
  - gis데이터_x01 : git_위도 + gis_경도 + git_시작일자 + gis_종료일자
                + gis_지역코드 + gis_위치명
  ```

  우편번호 테이블과 조인하는 부분도 비효율이 있어서 튜닝했지만, 여기서 설명하고자 하는 핵심 내용인 아래 gis데이터 쿼리 부분만 따로 떼서 분석해 보자. 여기서 쓰인 숫자 1은 1km를 의미한다.

  ```
  select *
  from   gis데이터
  where  gis_위도 between :승객위도 - 1 and :승객위도 + 1
  and    gis_경도 between :승객경도 - 1 and :승객경도 + 1
  and    sysdate between gis_시작일자 and gis_종료일자
  ```

  특징적인 것은, 조건절이 모두 between 범위검색 조건이라는 사실이다. 따라서 인덱스 스캔 범위는 인덱스 선두 컬럼인 'gis_위도' 컬럼에 대한 between 조건에 의해 거의 결정된다.

  데이터 분포를 살펴보자. gis데이터 테이블에는 당일치만 보관(전일 데이터는 백업 후 곧바로 삭제)하므로 당일 영업이 시작되는 시점에는 조회 속도가 아주 빠르다.
  하지만 시간이 흘러 밤 늦은 시간이 되면, 고객의 특정 위치 기준으로 위도상 좌우 1km 이내에 평균 100만 개 레코드가 쌓여 매우 느려진다.
  gis_위도 컬럼에 대한 between 조건에 의해 인덱스를 스캔해야 할 건수가 100만 건이나 되니 당연하지 않겠는가.

  어떻게 튜닝하면 좋을까? 지금까지 설명한 인덱스 스캔 원리상 현재 데이터 모델로는 과도한 인덱스 스캔 범위를 줄일 방법은 없다.

  여러 가지 고민을 하던 차에 필자와 같이 튜닝에 참여했던 동료 컨설턴트가 아이디어를 냈다. 반경 1km 이내를 한 번에 조회하지 말고 50m, 200, 1km 순으로 나눠서 쿼리하자는 것이다.
  어차피 가장 가까운 데 위치한 하나의 택시를 찾는 게 목적이므로 그렇게 세 구간으로 나누어 쿼리하면 대부분 첫 쿼리에서 찾게 된다.
  따라서 기존보다 인덱스 스캔량을 1/20로 줄일 수 있어 쿼리 성능을 그만큼 향상시킬 수 있다.

  실제 적용해 보니 아주 성공적이었다. 아래는 반경 50m 이내에서 가장 가까운 곳에 위치한 택시를 찾는 쿼리다.

  ```
  select decode(sign(b.우편번호코드-40000), 1, '', b.지역명1||' ')
       || nvl(b.지역명2, '') || ' ' || a.gis_위치명 위치명
  from   (select gis_지역코드, gis_위치명
               , sqrt(power((a.gis_위도-:승객위도)*111000,2)+
                      power((a.gis_경도-:승객경도)*88000,2)) 거리
          from   gis데이터
          where  gis_위도 between :승객위도 - 0.05 and :승객위도 + 0.05
          and    gis_경도 between :승객경도 - 0.05 and :승객경도 + 0.05
          and    sysdate between gis_시작일자 and gis_종료일자
          order by 거리
          ) a, 우편번호 b
  where   b.우편번호코드 = a.gis_지역코드
  and     rownum<=1;
  ```

  반경 200m와 1km 이내에서 가장 가까운 택시를 찾을 때는 0.05를 각각 0.2와 1로 바꿔주기만 하면 된다.

  우편번호와 조인하는 부분도 눈여겨볼 필요가 있는ㄴ데, 최종 건수는 항상 한 건이므로 미리 조인하지 않고 최종 한 건에 대해서만 조인하도록 변경하였다.

  데이터베이스 Call 최소화 원리(1권 5장)에 따르면 여러 개로 나누어 실행하던 SQL을 하나로 통합하는 것이 효과적이다.
  하지만 여기서는 거꾸로 하나의 SQL로 처리하던 것을 두 번, 세 번 나누어 처리함으로써 성능을 개선한 재미있는 사례다.

<br/>

## (6) 같은 컬럼에 두 개의 범위검색 조건 사용 시 주의 사항
앞에서는 다른 컬럼에 각각 범위검색 조건을 사용하는 경우를 살펴봤는데, 같은 컬럼에 두 개의 범위검색 조건을 사용할 떄도 세심한 주의가 필요하다.

도서 조회용 프로그램을 개발 중이라고 하자. 예를 들어 '오라클'을 키워드로 입력하면, '오라클'로 시작하는 모든 도서가 조회돼야 한다.
한 화면에 10개씩 출력되도록 하는 것이 업무 요건이면, 흔히 아래와 같은 패턴으로 SQL을 작성한다.
```
select *
from (
  select rownum rnum, 도서번호, 도서명, 가격, 저자, 출판사, isbn
  from (
    select 도서번호, 도서명, 가격, 저자, 출판사, isbn
    from   도서
    where  도서명 like :book_nm || '%'
    order by 도서명
  )
  where rownum <= 100
)
where rnum >= 91 → 10 페이지만 출력
```
도서명 컬럼에 인덱스가 있다면 첫 번째 rownum 조건(rownum <= 100)에 해당하는 레코드만 읽고 멈출 수 있다.
count(stopkey) 오퍼레이션이 작용하기 때문이며, 사용자들이 앞쪽 일부 레코드만 주로 본다면 위 쿼리도 만족스런 속도를 보인다. 표준적인 페이지 처리 구현 패턴으로 가장 적당하다고 하겠다.

그런데 뒤쪽 어느 페이지로 이동하더라도 빠르게 조회되도록 구현해야 한다면?
앞쪽 레코드를 스캔하지 않고 해당 페이지 레코드로 바로 찾아가도록 해야 하는데, 아래는 첫 번째 페이지를 출력하고 나서 '다음' 버튼을 누를 때의 구현 예시다.

```
select *
from (
    -- '이전' 페이지에서 출력된 마지막 레코드와 이름이 같은 도서가 있을 수 있다.
    -- 그럴 때 '현재' 페이지에는 '이전' 페이지 마지막 레코드와 이름이 같으면서
    -- rowid가 큰 도서부터 출력한다.
    -- 인덱스 키 값이 같을 때 rowid 순으로 정렬된다는 특성을 이용하는 것이다.
    select /*+ index(도서 도서명_idx) */
           rowid rid, 도서번호, 도서명, 가격, 저자, 출판사, isbn
    from   도서
    where  도서명 like :book_nm || '%'
    and    도서명 = :last_book_nm   -- 이전 페이지에서 출력된 마지막 도서명
    and    rowid > :last_rid      -- 이전 페이지에서 출력된 마지막 도서의 rowid
    union all
    -- '이전' 페이지 마지막 레코드와 이름이 같은 도서가 출력되고 나면
    -- 다른 이름의 도서를 출력한다. 사용자가 입력한 도서명 키워드(:book_nm)는
    -- like 조건절로 계속 포함시켜야 한다.
    select /*+ index(도서 도서명_idx) */
           rowid rid, 도서번호, 도서명, 가격, 저자, 출판사, isbn
    from   도서
    where  도서명 like :book_nm || '%'
    and    도서명 > :last_book_nm   -- 이전 페이지에서 출력된 마지막 도서명
)
where  rownum <= 10

Rows   Row Source Operation
------  ---------------------------------------------------------------------
    10  COUNT STOPKEY (cr=382 pr=0 pw=0 time=138 us)
    10    VIEW (cr=382 pr=0 pw=0 time=123 us)
    10      UNION-ALL (cr=382 pr=0 pw=0 time=104 us)
     1        FILTER (cr=4 pr=0 pw=0 time=71 us)
     1          TABLE ACCESS BY INDEX ROWID 도서 (cr=4 pr=0 pw=0 time=48 us)
     1            INDEX RANGE SCAN 도서명_IDX (cr=3 pr=0 pw=0 time=59 us)
     9          TABLE ACCESS BY INDEX ROWID 도서 (cr=378 pr=0 pw=0 time=13716 us)
     9            INDEX RANGE SCAN 도서명_IDX (cr=377 pr=0 pw=0 time=13567 us)
```
트레이스를 분석해 보면 union all 위쪽 브랜치에서 한 건, 아래쪽에서 9건을 읽었다. '이전' 페이지 마지막 레코드와 같은 이름을 가진 도서가 한 권 있었던 모양이다.

그런데 SQL에 비효율이 없어 보이는데도 union all 아래쪽 인덱스 스캔 단계에서만 377개 블록을 읽었다.
이유는, 도서명에 대한 범위검색 조건이 두 개인데 그 중 like 조건을 인덱스 액세스 조건으로 사용했기 때문이다.

예상실행계획에서 아래와 같은 Predicate 정보를 확인할 수 있다.
```
Predicate Information (identified by operation id):
---------------------------------------------------
  2 - access("도서명" LIKE :BOOK_NM||'%')
      filter("도서명" LIKE :BOOK_NM||'%' AND "도서명">:LAST_BOOK_NM)
```
사용자가 키워드로 입력한 '오라클' 도서를 처음부터 스캔하다가 :last_book_nm보다 큰 9개 레코드를 찾고서야 멈추었고, 사용자가 뒤쪽 페이지로 많이 이동할수록 그 비효율은 점점 커진다.

해결 방안은? '도서명 > :last_book_nm' 조건이 인덱스 액세스 조건으로 사용되도록 하면 된다. 아래와 같이 like 조건 좌변 컬럼을 가공해 보자.
```
select *
from (
    ...
    union all
    select ...
    from   도서
    where  rtrim(도서명) like :book_nm || '%'
    and    도서명 > :last_book_nm
)
where rownum <= 10

Rows   Row Source Operation
------  ---------------------------------------------------------------------
    10  COUNT STOPKEY (cr=7 pr=0 pw=0 time=143 us)
    10    VIEW (cr=7 pr=0 pw=0 time=120 us)
    10      UNION-ALL (cr=7 pr=0 pw=0 time=103 us)
     1        FILTER (cr=4 pr=0 pw=0 time=68 us)
     1          TABLE ACCESS BY INDEX ROWID 도서 (cr=4 pr=0 pw=0 time=47 us)
     1            INDEX RANGE SCAN 도서명_IDX (cr=3 pr=0 pw=0 time=58 us)
     9          TABLE ACCESS BY INDEX ROWID 도서 (cr=3 pr=0 pw=0 time=152 us)
     9            INDEX RANGE SCAN 도서명_IDX (cr=2 pr=0 pw=0 time=80 us)
```
부등호 조건을 만족하는 첫 번째 레코드부터 스캔을 시작했기 때문에 인덱스에서 스캔한 블록 수가 단 2개로 줄었다.

### [OR-Expansion을 이용하는 방법과 주의 사항]
아래처럼 use_concat 힌트를 사용하면 union all을 사용할 떄보다 SQL 코딩량을 줄일 수 있다.
OR 조건에 대한 expansion(union all 분기)이 일어나면 뒤쪽 조건절이 먼저 실행된다는 특징을 이용한 것이다.

```
select /*+ index(도서 도서명_idx) use_concat ordered_predicates */
       rowid rid, 도서번호, 도서명, 가격, 저자, 출판사, isbn
from   도서
where  도서명 like :book_nm || '%'
and  ((도서명 > :last_book_nm)
      or
      (도서명 = :last_book_nm and rowid > :last_rid) )
and    rownum <= 10
```
주의할 점은, 버전에 따라 실행되는 순서가 달라진다는 사실이다.
9i까지는 I/O 비용 모델, CPU 비용 모델을 불문하고 뒤쪽에 있는 조건 값을 먼저 실행하지만 10g CPU 비용 모델에서는 계산된 카디널리티가 낮은 쪽을 먼저 실행한다.

따라서 10g에서 값 분포에 상관없이 항상 뒤쪽에 있는 조건식이 먼저 처리되도록 하려면 ordered_predicates 힌트를 명시해야 한다.
- 상식적으로 부등호(>)보다 '=' 조건의 선택도가 낮고 카디널리티도 낮겠지만 옵티마이저가 사용하는 내부규칙에 의해 역전될 수도 있다.
  예를 들어, 부등호 조건을 변수로 비교할 때는 '5% 규칙'을 사용하기 때문에 선택도가 고정된 반면 '=' 조건의 선택도는 실제 데이터 분포에 의해 결정된다.
  따라서 부등호보다 '=' 조건의 선택도가 더 높게 구해질 수 있다.

### [rowid를 concatenation하면 결과에 오류 발생]
참고로, 아래처럼 작성해도 될 것 같지만 결과가 달라지므로 사용해선 안 된다.
```
select /*+ index(도서 도서명_idx) */
rowid rid, 도서번호, 도서명, 가격, 저자, 출판사, isbn
from   도서
where  도서명 like :book_nm || '%'
and    도서명 >= :last_book_nm
and    lpad(도서명, 50) || rowid > lpad(:last_book_nm, 50) || :last_rid
and    rownum <= 10
```
굵게 표시한 부분은, '도서명 >= :last_book_nm' 조건에 의해 선택된 레코드 중 도서명이 같으면 rowid 값 비교에 의해 한 번 더 필터링이 이루어지도록 한 것인데, 이는 내부적으로 아래와 같은 형태로
변환이 일어난다.
```
and    lpad(도서명, 50) || rowidtochar(rowid) > lpad(:last_book_nm, 50) || :last_rid
```
그리고 문자형으로 변환된 rowid는 rowid 값 그대로 비교할 때와 정렬순서가 다르다. 아래 결과를 참조하기 바란다.
```
SQL> select greatest('AAAH+WAAJAAAHxTAA9', 'AAAH+WAAJAAAHxTAA+') from dual;

GREATEST('AAAH+WAAJAAAHxTAA9', 'AAAH+
-------------------------------------
AAAH+WAAJAAAHxTAA9                        --> Char로 비교했을 때의 결과

SQL> select greatest( chartorowid('AAAH+WAAJAAAHxTAA9')
                    , chartorowid('AAAH+WAAJAAAHxTAA+') ) from dual;


GREATEST(CHARTOROW
------------------
AAAH+WAAJAAAHxTAA+                        --> ROWID로 비교했을 때의 결과
```

첫 페이지에서 출력한 마지막 rowid보다 큰 값을 조회하는데, 문자형으로 변환되는 바람에 비교되는 값들의 순서가 서로 역전된다면 쿼리 결과집합이 틀려질 수 있음을 이해하겠는가?

### [인덱스를 스캔하면서 rowid를 필터링할 때 발생하는 비효율]
아래는 '이전' 페이지에서 출력된 마지막 레코드와 이름이 같은 도서를 찾는 쿼리(union all 위쪽 브랜치)다. 여기에는 비효율이 없는가?
```
select /*+ index(도서 도서명_idx) */
       rowid rid, 도서번호, 도서명, 가격, 저자, 출판사, isbn
from   도서
where  도서명 like :book_nm || '%'
and    도서명 = :last_book_nm   -- 이전 페이지에서 출력된 마지막 도서명
and    rowid > :last_rid      -- 이전 페이지에서 출력된 마지막 도서의 rowid
```
rowid를 이용한 액세스이므로 비효율 없이 항상 완벽한 속도를 보장할 거 같지만 그렇지 않다.
rowid를 가지고 '=' 조건으로 바로 액세스할 땐 어떤 액세스보다 빠르지만 인덱스를 스캔하면서 rowid를 필터링할 때는 아니다.

인덱스 rowid는 리프 블록에만 있기 때문에 이를 필터링하려면 일단 다른 액세스 조건만으로 리프 블록을 찾아가야 한다.
거기서 스캔을 시작해 rowid를 필터링해야 하므로 '도서' 테이블에 같은 도서명을 가진 레코드가 "아주" 많다면 뒤 페이지로 이동할수록 비효율도 커진다.

비효율 없는 가장 완벽한 구현을 위해서라면 도서명_idx 인덱스 뒤쪽에 도서번호(PK컬럼)를 붙이고 쿼리를 아래와 같이 바꾸면 된다.
```
create index 도서명_idx on 도서(도서명, 도서번호) ;

select /*+ index(도서 도서명_idx) */ 도서번호, 도서명, 가격, 저자, 출판사, isbn
from   도서
where  도서명 like :book_nm || '%'
and    도서명 = :last_book_nm       -- 이전 페이지에서 출력된 마지막 도서명
and    도서번호 > :last_book_no      -- 이전 페이지에서 출력된 마지막 도서의 rowid
```
하지만 인덱스 뒤에 PK 컬럼을 붙여가며 개발하는 것이 쉽지만은 않다. 더구나 PK가 다중 컬럼으로 구성된다면 구현하기가 더 복잡해진다.
따라서 중복 값이 아주 많은 경우가 아니라면 rowid를 이용하는 방안이 현실적이다.

<br/>

## (7) Between과 Like 스캔 범위 비교
월별로 집계된 테이블에서 2009년 1월부터 12월 데이터를 조회하고자 할 때 흔히 아래와 같이 like 연산자를 사용한다.
```
select * from 월별고객별판매집계
where 판매월 like '2009%';
```
원래 아래와 같이 between 연산자를 사용하는 것이 더 정확한 방식(예를 들어, 월 집계 테이블에 년도별 집계를 함께 관리하려고 '2009' 또는 '200900' 같은 값을 넣은 경우를 가정해 보라)임에도
개발자들이 like를 더 선호하는 이유는 간단하다. like로 코딩하는 것이 더 단순하고 쉽기 때문이다.
```
select * from 월별고객별판매집계
where 판매월 between '200901' and '200912'
```
like와 between은 둘 다 범위검색 조건으로서, 앞에서 설명한 범위검색 조건을 사용할 때의 비효율 원리도 똑같이 적용된다.
하지만 검색을 위해 입력한 값과 테이블의 실제 데이터 상황에 따라 둘 간의 인덱스 스캔량이 다를 수 있다. 결론부터 말해, between을 사용한다면 적어도 손해 볼 일은 없다.
(Range 파티션 테이블을 쿼리할 때도 like 보다 가급적 between 연산자를 사용하는 편이 낫다.)

예제를 통해 살펴보자. 앞서 Index Skip Scan을 이용한 비효율 해소 원리를 설명하면서 '월별고객별판매집계' 테이블을 예로 들었는데, 그 테이블에 2009년 1월과 2월 판매 데이터가 추가로 입력되었다고 하자.
판매구분으로는 'A'와 'B' 두 개의 값이 존재하고, 각각 8.3%와 91.7%의 비중을 차지한다.

위와 같은 데이터 상황에서 아래 세 개의 쿼리를 실제 수행해 보면, 결과는 같지만 I/O 발생량에 큰 차이를 보이는 것을 관찰할 수 있다.
```
< 쿼리 1 >
select count(*)
from   월별고객별판매집계 t
where  판매월 BETWEEN '200901' and '200902'
and    판매구분 = 'A';

< 쿼리 2 >
select count(*)
from   월별고객별판매집계 t
where  판매월 LIKE '2009%'
and    판매구분 = 'A';

< 쿼리 3 >
select count(*)
from   월별고객별판매집계 t
where  판매월 >= '200901'
and    판매월 <  '200903'
and    판매구분 = 'A';
```

between 연산자를 사용한 쿼리 1은, 2009년 1월 데이터는 모두 읽더라도 2009년 2월 데이터만큼은 판매구분이 'A'인 데이터만 읽고 멈춘다.
반면 like 연산자를 사용한 쿼리 2는 2009년 1월과 2월 데이터를 모두 읽는다.

쿼리 3처럼 조회하면 '200902' || 'A' 구간만 읽고서 멈추지 못해 결국 like를 사용한 쿼리 2와 같은 스캔량을 보인다.

이번에는 'A'와 'B' 값의 비중이 각각 91.7%와 8.3%로 역전되도록 값을 입력(스캔량에 차이를 크게 나타내 보이려고 바꾸는 것일 뿐 스캔 범위 결정 원리와는 무관)한 상태에서 판매구분이 'B'인 레코드를
찾는 경우를 살펴보자.

아래 세 개의 쿼리를 실제 수행해 보면, 여기서도 I/O 발생량에 큰 차이를 보이는 것을 관찰할 수 있다.
```
< 쿼리 4 >
select count(*)
from   월별고객별판매집계 t
where  판매월 BETWEEN '200901' and '200902'
and    판매구분 = 'B';

< 쿼리 5 >
select count(*)
from   월별고객별판매집계 t
where  판매월 LIKE '2009%'
and    판매구분 = 'B';

< 쿼리 6 >
select count(*)
from   월별고객별판매집계 t
where  판매월 BETWEEN '200900' and '200902'
and    판매구분 = 'B';
```
between 연산자를 사용한 쿼리 4는, 2009년 2월 데이터는 모두 읽더라도 2009년 1월 데이터만큼은 판매구분이 'B'인 데이터만 읽는다.
반면 like 연산자를 사용한 쿼리 5는 2009년 1월과 2월 데이터를 모두 읽어야 한다. 쿼리 5가 1월 데이터를 모두 스캔한 이유는, 리프 블럭에 실제 없는 값('2009')으로 조회했기 때문이다.

between 이더라도 쿼리 6처럼 시작 값을 '200900'으로 입력하고 조회하면 like를 사용한 쿼리 5와 같은 스캔량을 보이게 된다.

like라고 하더라도 아래 쿼리 7과 같이 인덱스에서 실제 찾아지는 값('200901')을 입력했을 때는 스캔 범위를 줄일 수 있다(쿼리 4,5,6과 결과집합은 다름).
즉, 2009년 1월 중 'B'인 데이터 구간만 정확히 찾아서 스캔하게 된다.
```
< 쿼리 7 >
select count(*)
from   월별고객별판매집계 t
where  판매월 LIKE '200901%'
and    판매구분 = 'B';

< 쿼리 8 >
select count(*)
from   월별고객별판매집계 t
where  판매월 = '200901'
and    판매구분 = 'B';
```
따라서 쿼리 8처럼 '=' 조건으로 조회할 때와 비교해도 전혀 비효율이 없다.
물론 같은 판매월 조건으로 [판매구분 = 'A']를 검색할 때는 '200902' 데이터를 만나기 전까지 스캔을 멈추지 못해 like가 '='이나 between 조건일 때보다 비효율적이다.

### [범위검색 조건의 스캔 시작점 결정 원리]
지금부터 설명할 인덱스 스캔 시작점 결정 원리는 이해하기 쉽지 않은 내용이다.
정확한 원리를 이해하지 못하더라도 대충 어떤 의미인지를 파악하는 것만으로 충분하다고 하겠으며, 결론부터 말하면 범위검색 조건 뒤를 따르는 조건절은 스캔 범위를 줄이는 데에 영향을 미칠 수도 있고 그렇지
않을 수도 있다.
사용자가 조건 비교를 위해 입력한 값이나 테이블의 실제 데이터 상황에 따라 달라지며, 적어도 between이 like보다 더 넓은 범위를 스캔하는 경우는 없으므로 가급적 between을 사용하기 바란다는 내용이다.

인덱스 컬럼 조건에 대해 범위검색 조건이 나타나면 이후 조건은 인덱스 스캔 범위를 줄여주지 못해 비효율이 생긴다.
하지만 방금 전에 설명했듯이 범위검색 조건 뒤에 사용된 조건들도 제한적이나마 스캔 범위를 줄이는 데에 기여할 수 있는데, 지금부터 그 원리를 살펴보자.

쿼리 2나 3에서 '200902' 구간 끝까지 읽는 이유는 설명하지 않아도 쉽게 이해하리라 믿는다. 하지만 쿼리 4,5,6 간의 스캔 시작점에 차이가 생기는 이유를 이해하는 것은 쉽지 않다.

먼저, 1절에서 설명한 인덱스 구조와 탐색 원리를 한번 상기하기 바란다.

쿼리 5부터 살펴보자. 쿼리 5처럼 like 조건으로 검색할 때는 [판매월 = '2009'이고 판매구분 = 'B']인 레코드를 목표로 수직적 탐색이 이루어진다.
브랜치 블록에서는 뒤쪽 엔트리부터 스캔을 시작해 비교 값보다 작은 값을 만나는 순간 거기서 가리키는 하위 노드로 이동한다고 했다.

그런 식으로 내려가다 보면 '200812' || 'B'인 레코드가 담긴 가장 마지막 리프 블록에 도달하게 된다. 그렇게 도달한 리프 블록에는 '200901' || 'A'인 첫 번째 레코드가 포함돼 있을 가능성이 높다.
만약 그 값이 포함되지 않는다면 바로 다음 리프 블록의 처음 레코드 키 값이 '200901' || 'A'인 경우다.(실제 데이터를 그려가며 시뮬레이션해 보지 않으면 이해하기 쉽지 않은 내용이다.)

어쨌든 지금 수직 탐색 과정에서 사용한 비교 조건이 '200812' || 'B'와 '200901' || 'A' 사이 값이므로 이 블록부터 스캔한다면 원하는 값을 모두 찾을 수 있다.
이 때문에 불필요하게 '200901' || 'A' 구간까지 읽게 되는 것이고, 결론적으로 판매구분 = 'B' 조건이 스캔 범위를 줄이는 데에 기여하지 못했다.

쿼리 4와 같이 between 일 때는 [판매월 = '200901'이고 판매구분 = 'B']인 레코드를 목표로 (앞에서는 판매월 검색 기준이 '2009'이었음) 수직적 탐색이 이루어진다.
여기서도 마찬가지로 브랜치 블록에서 뒤쪽 엔트리부터 스캔하다가 위 조건보다 작은 값을 만나는 순간 거기서 가리키는 하위 노드로 이동한다.
그러다 보면 '200901' || 'B' 인 첫 번째 레코드가 담긴 리프 블록에 도달하거나, '200901' || 'A'인 레코드가 담긴 가장 마지막 리프 블록(이 리프 블록의 가장 마지막 레코드가
'200901' || 'A'이고, 바로 다음 리프 블록의 첫 번째 레코드가 '200901' || 'B'인 경우일 것임)에 도달하게 된다. 따라서 판매구분 = 'B' 조건이 스캔 범위를 줄이는 데에 큰 기여를 한다.

여기서 키 포인트는 실제 테이블에 존재하는 값을 수직적 탐색 조건으로 사용했다는 점이다.
만약 같은 between이더라도 쿼리 6과 같이 실제 테이블에 없는 데이터 값을 입력하고 조회한 경우에는 '200812' || 'B'인 레코드가 담긴 가장 마지막 리프 블록부터 스캔을 시작하게 되므로 불필요하게
'200901' || 'A' 구간까지 읽게 된다.

반대로, like 조건이더라도 쿼리 7과 같이 실제 테이블에 있는 데이터 값을 입력하고 조회할 때는 판매구분 = 'B' 조건이 스캔 범위를 줄이는 데에 큰 역할을 하였다.
즉, '200901' || 'A'인 구간을 생략하고 '200901' || 'B' 구간만 정확히 읽는다.

<br/>

## (8) 선분이력의 인덱스 스캔 효율
범위검색 조건 뒤를 잇는 또 다른 범위검색 조건도 인덱스 스캔 범위를 줄이는 역할을 일부 할 수 있지만 일반적으로 그 영향력은 크지 않다.
특히 항상 두 개의 부등호 조건을 함께 사용하는 선분이력에선 데이터 특성상 두 번째 부등호 조건이 스캔 범위를 줄이는 데 전혀 도움을 주지 못한다.
- between은 두 개의 부등호(<=, >=)를 함께 사용한 것과 같다.

두 개의 부등호 조건을 사용하는 선분이력 조회의 특성을 제대로 이해하지 못해 인덱스 구성을 잘못하면 성능이 많이 나빠질 수 있다.
그리고 어느 시점을 주로 조회하느냐에 따라서도 인덱스 스캔 효율이 많이 달라지므로 인덱스 설계 및 쿼리 작성 시 매우 세심한 주의가 필요하다.

### [선분이력이란?]
예를 들어 고객의 변경이력을 관리할 때의 이력의 시작시점만을 관리하는 것을 '점이력' 모델이라고 하고, 시작시점과 종료시점을 함께 관리하는 것을 '선분이력' 모델이라고 한다.

점이력으로 관리할 때 PK가 [고객번호 + 변경일자]로 구성된다면, 선분이력으로 관리할 때는 [고객번호 + 시작일자 + 종료일자]로 구성된다.
그리고 가장 마지막 이력의 종료일자는 항상 '99991231'(시간까지 관리할 때는 '99991231235959')로 입력해 두어야 한다.

이력을 이처럼 선분형태(예를 들어, 2009/05/01 ~ 2009/06/13)로 관리하면 무엇보다 쿼리가 간단해진다는 것이 가장 큰 장점이다.
예를 들어, 123번 고객의 2009년 5월 5일 시점 이력을 조회하고자 할 때 아래처럼 between 조인을 이용해 간편하게 조회할 수 있다.
```
select a.고객번호, a.고객명, a.연락처, a.주소, b.연체금액, b.연첵애ㅝㄹ수
from   고객 a, 고객별연체금액 b
where  a.고객번호 = '123'
and    b.고객번호 = a.고객번호
and    '20090505' between b.시작일 and b.종료일 ;
```
데이터를 점이력으로 관리할 때 아래처럼 서브쿼리를 이용해 복잡하게 쿼리하던 것과 비교해 보기 바란다.
```
select a.고객번호, a.고객명, a.연락처, a.주소, b.연체금액, b.연첵애ㅝㄹ수
from   고객 a, 고객별연체금액 b
where  a.고객번호 = '123'
and    b.고객번호 = a.고객번호
and    b.연체변경일자 = (select max(연체변경일자)
                     from    고객별연체금액
                     where   고객번호 = a.고객번호
                     and     변경일자 <= '20090505');
```
쿼리가 간단하면 아무래도 성능상 유리할 때가 많다. 대신, 이력이 추가될 때마다 기존 최종 이력의 종료일자(또는 종료일시)도 같이 변경해 주어야 하는 불편함이 있다.
이 때문에 DML 성능이 나빠질 뿐만 아니라 이력 데이터를 관리(잘못된 과거 이력 데이터를 일괄 보정하는 등)하는 프로그램이 복잡해 진다.

중요한 또 한 가지 단점은, 개체 무결성을 사용자가 직접 관리해 주어야 한다는 것이다.
선분이력의 개체 무결성을 확보하려면 선분의 중복(예를 들어, 5/5 ~ 5/18, 5/15 ~ 6/23 두 개의 선분이 입력되면 5/15 ~ 5/18 구간에 중복 발생)이 없어야 한다.
점이력일 때는 PK 제약을 설정하는 것만으로 개체 무결성이 완벽히 보장되지만, 선분이력일 때는 선분이 겹치거나 끊기지 않도록 방지하는 기능을 DBMS가 제공하지 않아 개체 무결성이 보장되지 않는다.
PK를 [고객번호 + 시작일자] 또는 [고객번호 + 종료일자]로 구성하면 PK 중복은 피할 수 있지만 선분의 중복은 피할 수 없다는 얘기다.

선분이력의 개체 무결성은 어차피 애플리케이션에서 구현할 수 밖에 없으므로 프로그래밍할 때 동시성 제어 기법을 철저히 적용해야 하는 수고가 뒤따르고, 그럼에도 사용자가 직접 데이터를 입력/수정하는 과정에서
정합성이 깨지는 문제는 (트리거를 사용하지 않는 한) 근본적인 해결이 불가능하다.

RDBMS 설계 사상에 맞지 않게 PK 값이 변경된다는 사실도 잦은 시비의 대상이 되곤 한다.
PK 제약만으론 개체 무결성이 보장되지 않으니 인덱스 스캔 효율이라도 높이기 위해 통상 PK 구성에 시작일자와 종료일자가 모두 포함되도록 설계하기 때문이다.
[고객번호 + 시작일자] 또는 [고객번호 + 종료일자]로 PK를 구성한 상태에서 update/insert 순서를 잘 조절하면 PK 값이 변경되지 않도록 구현할 수는 있지만, 그때는 시작일자와 종료일자를 모두 포함한
인덱스를 별도로 생성해 주어야 한다.

선분이력 모델과 관련해 이처럼 많은 이슈들이 존재하지만 본서는 모델링을 다루는 책이 아니므로 더 이상 깊이 설명하지는 않겠다.

### [선분이력 기본 조회 패턴]

### [[시작일 + 종료일] 구성일 때 최근 시점 조회]

### [[시작일 + 종료일] 구성일 때 과거 시점 조회]

### [[종료일 + 시작일] 구성일 때 최근 시점 조회]

### [[종료일 + 시작일] 구성일 때 과거 시점 조회]

### [중간 시점 조회]
최초 이력이나 최근 이력을 조회하는 것이 아니라 중간 시점(예를 들어, 2003년 10월 10일) 이력을 조회할 때는 인덱스 구성을 어떻게 하든 어느 정도의 비효율을 감수해야만 한다.

하지만 중간 시점을 조회할 때도 아래처럼 rownum <= 1 조건을 활용하면 단 한 건만 스캔하고도 원하는 이력 레코드를 빠르게 찾을 수 있다.

```
# 인덱스 구성이 [고객번호 + 시작일 + 종료일]일 떄

select /*+ index_desc(a idx_x01) */ *
from   고객별연체금액 a
where  고객번호 = '123'
and    '20031010' between 시작일 and 종료일
and    rownum <= 1

# 인덱스 구성이 [고객번호 + 종료일 + 시작일]일 때

select *
from   고객별연체금액 a
where  고객번호 = '123'
and    '20031010' between 시작일 and 종료일
and    rownum <= 1
```

### [선분이력 스캔 효율을 높이는 방법 요약]
복잡하다고 느낄 것이므로 지금까지 설명한 내용을 요약해보자.

선분이력처럼 between 검색 조건이 사용될 때는 어느 시점을 주로 조회하느냐에 따라 인덱스 구성 전략을 달리 가져가야 한다.
최근 데이터를 주로 조회한다면 [종료일 + 시작일] 순으로 구성하는 것이 효과적이며, 오래된 과거 데이터를 주로 조회한다면 [시작일 + 종료일] 순으로 구성하는 것이 효과적이다.

rownum과 index_desc 힌트를 적절히 사용하면 인덱스 구성이 어떻든지 간에 항상 필요한 한 건만 스캔하도록 할 수 있다.
인덱스 구성이 [시작일 + 종료일]일 때는 index_desc 힌트와 rownum <= 1 조건을 추가해 주고, [종료일 + 시작일] 일 때는 rownum <= 1 조건만 추가해 주면 된다.

중간 시점을 조회할 때도 이 방식을 사용하면 인덱스 구성과 상관 없이 빠르게 데이터를 찾을 수 있다.

업무적으로 미래 시점 데이터르 미리 입력하는 경우가 없다면, 현재 시점 데이터(=가장 마지막 이력)를 조회할 때는 between을 사용하기보다 [종료일 = '99991231'] 조건을 사용하는 것이 효과적이다.

여기서는 단일 선분이력 테이블을 조회할 때의 스캔 효율을 높이는 방법에 대해서만 살펴봤고, 다른 테이블과 between 조인할 때 생기는 성능 이슈와 해법에 대해서는 2장 조인 원리와 활용편에서 다룬다.

<br/>

## (9) Access Predicate와 Filter Predicate
explain plan 명령을 통해 실행계획을 수집하고서 dbms_xplan 패키지(@?/rdbms/admin/utlxpls.sql 참조)를 통해 실행계획을 출력해 보면 아래와 같이 Predicate 정보를 확인할 수 있는데,
이는 오라클 9i부터 plan_table에 추가된 access_predicates와 filter_predicates 컬럼으로부터 가져온 값이다. 그리고 10gR2부터는 Autotrace 명령을 통해서도 Predicate 정보를 출력해 볼 수 있다.
```
SQL> create index emp_x01 on emp(deptno, job, sal, ename, mgr, comm);

SQL> set autotrace traceonly explain
SQL> select /*+ ordered use_nl(e) index(e emp_x01) */ *
  2  from   dept d, emp e
  3  where  d.loc = 'CHICAGO'
  4  and    e.deptno = d.deptno
  5  and    e.job like 'SALE%'
  6  and    e.job between 'A' and 'Z'
  7  and    e.sal >= 1000
  8  and    e.ename like '%A%'
  9  and    trim(e.ename) = 'ALLEN'
 10  and    e.comm >= 300
 11  and    to_char(e.hiredate, 'yyyymmdd') like '198102%' ;

------------------------------------------------------------------------------
| Id  | Operation                    | Name    | Rows  | Bytes | Cost  (%CPU)|
------------------------------------------------------------------------------
|   0 | SELECT STATEMENT             |         |     1 |    57 |     6    (0)|
|*  1 |   TABLE ACCESS BY INDEX ROWID| EMP     |     1 |    37 |     2    (0)|
|   2 |     NESTED LOOPS             |         |     1 |    57 |     6    (0)|
|*  3 |       TABLE ACCESS FULL      | DEPT    |     1 |    20 |     4    (0)|
|*  4 |       INDEX RANGE SCAN       | EMP_X01 |     1 |       |     2    (0)|
------------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
1 - filter(TO_CHAR(INTERNAL FUNCTION("E"."HIREDATE"), 'yyyymmdd') LIKE '198102%')
3 - filter("D"."LOC"='CHICAGO')
4 - access("E"."DEPTNO"="D"."DEPTNO" AND "E"."JOB" LIKE 'SALE%' AND
           "E"."SAL">=1000 AND "E"."COMM">=300 AND "E"."SAL" IS NOT NULL)
    filter("E"."ENAME" LIKE '%A%' AND "E"."JOB" LIKE 'SALE%' AND
           "E"."SAL">=1000 AND TRIM("E"."ENAME")='ALLEN' AND
           "E"."JOB">='A' AND "E"."JOB"<='Z' AND "E"."COMM">=300
```
인덱스를 경유해 테이블을 액세스할 때는 아래와 같이 최대 3가지 Predicate 정보가 나타날 수 있다.

- [1] 인덱스 단계에서의 Access Predicate (id=4 access 부분)
- [2] 인덱스 단계에서의 Filter Predicate (id=4 filter 부분)
- [3] 테이블 단계에서의 Filter Predicate (id=1 filter 부분)

인덱스를 경유하지 않고 테이블 전체를 스캔할 때는 아래와 같이 항상 Filter Predicate 단 한 가지만 나타날 수 있다.

- [4] 테이블 단계에서의 Filter Predicate (id=3 filter 부분)

1번 '인덱스 단계에서의 Access Predicate'는 인덱스 스캔 범위를 결정하는 데에 영향을 미치는 조건절을 의미한다.
앞에서 설명했다시피 인덱스 컬럼에 대한 조건절은, 설령 범위검색 조건을 뒤따르는 조건(위 쿼리에서 sal >= 1000)이거나 선행 컬럼이 조건절에서 누락될지라도(위 쿼리에서 comm >= 300),
액세스 범위를 결정하는 데에 기여하므로 대부분 Access Predicate에 포함된다.

아래 경우에는 인덱스 스캔 범위를 결정하는 데에 전혀 영향을 미치지 않기 때문에 Access Predicate에서 제외된다.

- 좌변 컬럼을 가공한 조건절
  - 위 쿼리에서 trim(e.ename) = 'ALLEN'
- 왼쪽 '%' 또는 양쪽 '%' 기호를 사용한 like 조건
  - 위 쿼리에서 ename like '%A%'
- 같은 컬럼에 대한 조건절이 두 개 이상일 때, 인덱스 액세스 조건으로 선택(위 쿼리에서 job like 'SALE%')되지 못한 다른 조건절
  - 위 쿼리에서 job between 'A' and 'Z'


위와 같은 경우를 제외하면 앞에서 누차 강조했듯이, **수직적 탐색 과정에서 모든 인덱스 컬럼을 비교 조건으로 사용한다**는 사실을 반드시 기억하기 바란다.
물론 수평적 탐색 종료 지점을 결정하는 비교조건으로도 사용된다.

2번 '인덱스 단계에서의 Filter Predicate'는 테이블로의 액세스 여부를 결정짓는 조건들을 의미한다.
첫 번째 나타나는 범위검색 조건부터 이후 모든 조건절 컬럼들이 여기에 포함되며, 조건절에서 누락된 컬럼 뒤쪽에 놓인 인덱스 컬럼들도 포함한다.

'테이블 액세스 단계에서의 Filter Predicate'(인덱스를 경유한 3번이나 경유하지 않은 4번 둘 다)는 테이블을 액세스하고 나 최종 결과집합으로의 포함여부를 결정짓는 조건절을 의미한다.
위 쿼리에서는 [to_char(e.hiredate, 'yyyymmdd') like '198102%']와 [d.loc = 'CHICAGO'] 조건절이 여기에 해당한다.

<br/>

## (10) Index Fragmentation
delete 작업 때문에 인덱스가 불균형(Unbalanced) 상태에 놓일 수 있다고 설명한 자료들을 볼 수 있다.
즉, 다른 리프 노드에 비해 루트 블록과의 거리가 더 멀거나 가까운 리프 노드가 생길 수 있다는 것인데, 오라클에서 이런 현상은 절대 발생하지 않는다.

B*Tree 인덱스의 'B'는 'Balanced'의 약자로서, 인덱스 루트에서 리프 블록까지 어떤 값으로 탐색하더라도 읽는 블록 수가 같음을 의미한다. 즉, 루트로부터 모든 리프 블록까지의 높이(height)가 동일하다.

불균형(Unbalanced)은 생길 수 없지만 Index Fragmentation에 의한 Index Skew 또는 Sparse 현상이 생기는 경우는 종종 있고, 이는 인덱스 스캔 효율에 나쁜 영향을 미칠 수 있다.

### [Index Skew]
Index Skew는 인덱스 엔트리가 왼쪽 또는 오른쪽에 치우치는 현상을 말한다.
예를 들어, 아래와 같이 대량의 delete 작업을 마치고 나면 인덱스 왼쪽에 있는 리프 블록들은 텅 비는 반면 오른쪽 블록들은 꽉 찬 상태가 된다.
```
SQL> create table t as select rownum no from dual connect by level <= 1000000 ;

SQL> create index t_idx on t(no) pctfree 0 ;

SQL> delete from t where no <= 500000;

SQL> commit;  → 이 시점에 freelist로 반환되지만 인덱스 구조는 그대로 남는다.
```
텅 빈 인덱스 블록은 커밋하는 순간 freelist로 반환되지만 인덱스 구조 상에는 그대로 남는다.
상위 브랜치에서 해당 리프 블록을 가리키는 엔트리가 그대로 남아 있어 인덱스 정렬 순서상 그곳에 입력될 새로운 값이 들어오면 언제든 재사용될 수 있다.
(재사용되더라도 이 경우에는 곧바로 freelist에서 제거되지 않으며 나중에 빈 블록을 찾기 위해 freelist를 스캔하는 프로세스에 의해 정리된다.)

새로운 값이 하나라도 입력되기 전 다른 노드에 인덱스 분할이 발생하면 그것을 위해서도 이들 블록이 재사용된다.
이때는 상위 브래치에서 해당 리프 블록을 가리키는 엔트리가 제거돼 다른 쪽 브랜치의 자식 노드로 이동하고, freelist에서도 제거된다.

레코드가 모두 삭제된 블록은 이처럼 언제든 재사용 가능하지만, 문제는 다시 채워질 때까지 인덱스 스캔 효율이 낮다는 데에 있다.
아래는 위 delete 문을 수행한 직후에 한 레코드를 읽기 위해 1,001개 블록을 읽게 됨을 보여준다.
```
SQL> set autotrace on statistics
SQL> select * from t where no > 0 and rownum <= 1;

        NO
----------
    500001

Statistics
---------------------------------------------------------
         0  recursive calls
         0  db block gets
      1001  consistent gets
       ...  .....
```
물론 맨 왼쪽부터 스캔하도록 조건을 주었기 때문이며, 값이 입력된 첫 번째 이후부터 스캔하도록 조건절(no > 500000)을 바꿔주면 빈 블록을 스캔하지 않아도 된다.
위와 같은 Index Skew 때문에 성능이 나빠지는 경우는 대개 Index Full Scan할 때다.

대량의 데이터를 매일 지웠다가 새로 입력하는 통계성 테이블일 때는 Index Skew가 발생하지 않도록 트랜잭션 패턴에 신경을 써야 한다.
예를 들어 보관주기가 3일인 일별고객별판매집계 테이블이 있는데, 배치 프로그램을 통해 아래 트랜잭션을 매일 밤 10시에 수행한다고 하자. PK 인덱스는 [판매일시 + 고객번호] 순으로 구성되었다.
```
delete from 일별고객별판매집계 where 판매일시 < trunc(sysdate) - 2;

insert into 일별고객별판매집계
select to_char(sysdate, 'yyyymmdd'), 고객번호, sum(판매량), sum(판매금액)
from   판매
where  판매일시 between trunc(sysdate) and trunc(sysdate+1)-1/24/60/60
group by 고객번호

commit;
```
PK 인덱스 왼쪽에 놓인 상당수 리프 블록들이 delete 문을 통해 모든 레코드가 지워지더라도 커밋하기 전까지는 freelist로 반환될 수 없다.
따라서 곧 이은 insert 과정에서 빈 블록이 많이 필요함에도 앞서 지운 블록들을 사용할 수 없어 새로운 공간을 할당받게 된다.

물론 빈 블록들은 그 다음 날 insert 과정에서 재사용되겠지만 delete 문에 의해 지워지는 블록들이 새로 생긴다. 결국 인덱스 왼쪽의 많은 블록들이 항상 빈 상태로 남아 인덱스 스캔 효율을 떨어뜨리게 된다.

반면 아래와 같이 delete 문 직후에 커밋을 수행하면 지워진 블록들이 곧바로 insert 과정에 재사용된다.
Index Skew를 두려워해 트랜잭션을 짧게 정의하는 것이 바람직하진 않지만 이 경우는 일반 사용자가 접근하지 않는 야간에 배치 프로그램을 통해서만 관리되는 통계성 테이블이므로 아래와 같이 처리해도
무방할 것이다. (업무적인 중요도와 트랜잭션이 실패했을 때 재생 가능한지 등에 따라 판단하기 바란다.)
```
delete from 일별고객별판매집계 where 판매일시 < trunc(sysdate) - 2;

commit;

insert into 일별고객별판매집계
select to_char(sysdate, 'yyyymmdd'), 고객번호, sum(판매량), sum(판매금액)
from   판매
where  판매일시 between trunc(sysdate) and trunc(sysdate+1)-1/24/60/60
group by 고객번호

commit;
```
필자가 방문했던 어떤 회사는 문장 단위로 커밋하는데도 아래와 같이 insert 문을 먼저 수행하는 바람에 Index Skew 현상을 겪고 있었다.
```
insert into 일별고객별판매집계
select to_char(sysdate, 'yyyymmdd'), 고객번호, sum(판매량), sum(판매금액)
from   판매
where  판매일시 between trunc(sysdate) and trunc(sysdate+1)-1/24/60/60
group by 고객번호

commit;

delete from 일별고객별판매집계 where 판매일시 < trunc(sysdate) - 2;

commit;
```
insert문에 의해 Skew가 해소되었다가 곧 이은 delete 문에 의해 왼쪽 리프 노드가 또다시 지워진다.
따라서 insert문과 delete문 수행순서를 바꾸지 않는 한 인덱스 왼쪽 리프 노드는 항상 빈 상태일 것이다.

### [Index Sparse]
Index Sparse는 인덱스 블록 전반에 걸쳐 밀도(density)가 떨어지는 현상을 말한다.

예를 들어, 아래와 같은 형태로 delete 작업을 수행하고 나면 t_idx 블록의 밀도는 50% 정도 밖에 되질 않는다.
100만 건 중 50만 건을 지우고 나서도 스캔한 인덱스 블록 수가 똑같이 2,001개인 것을 확인하기 바란다.
```
SQL> create table t as select rownum no from big_table where rownum <= 1000000 ;

SQL> create index t_idx on t(no) pctfree 0 ;

SQL> select /*+ index(t) */ count(*) from t where no > 0;

  COUNT(*)
----------
   1000000

Statistics
---------------------------------------------------------
         0  recursive calls
         0  db block gets
      2001  consistent gets
       ...  .....

SQL> delete from t where mod(no, 10) < 5;

500000 행이 삭제되었습니다.

SQL> commit;

SQL> select /*+ index(t) */ count(*) from t where no > 0;

  COUNT(*)
----------
    500000

Statistics
---------------------------------------------------------
         0  recursive calls
         0  db block gets
      2001  consistent gets
       ...  .....
```
지워진 자리에 인덱스 정렬 순서에 따라 새로운 값이 입력되면 그 공간은 재사용되지만 위와 같은 대량의 delete 작업이 있고 난 후 한동안 인덱스 스캔 효율이 낮다는 데에 문제가 있다.

왼쪽, 오른쪽, 중간 어디든 Index Skew처럼 블록이 아예 텅 비면 곧바로 freelist로 반환돼 언제든 사용가능하지만, Index Sparse는 지워진 자리에 새로운 값이 입력되지 않으면 영영 재사용되지
않을 수도 있다. 총 레코드 건수가 일정한데도 인덱스 공간 사용량이 계속 커지는 것은 대개 이런 현상에 기인한다.

### [Index Rebuild]
Fragmentation 떄문에 인덱스 크기가 계속 증가하고 스캔 효율이 나쁠 때는 아래와 같이 coalesce 명령을 수행해 주면 된다. 아래는 coalesce 명령을 수행하고 나서 조금 전 쿼리를 다시 수행한 결과다.
```
SQL> alter index t_idx coalesce;
SQL> select /*+ index(t) */ count(*) from t where no > 0;

Statistics
---------------------------------------------------------
         0  recursive calls
         0  db block gets
      1002  consistent gets
       ...  .....
```
coalesce 명령을 수행하면 인덱스 분할과 반대의 작업이 일어난다. 즉, 여러 인덱스 블록을 하나로 병합(merge)하고, 그 결과로서 생긴 빈 블록들은 freelist에 반환한다.
coalesce 명령을 수행해도 인덱스 세그먼트에 할당된 미사용 공간(HWM 아래쪽에서 freelist에 등록된 블록과 HWM 위쪽 미사용 블록)은 반환되지 않는다.
Index Fragmentation을 해소하면서 공간까지 반환하려면 아래와 같이 shrink 명령을 수행하면 된다. 단, shrink는 ASSM에서만 작동한다.
- 인덱스 분할은 트랜잭션 중에 동적으로 일어나지만 인덱스 병합은 명령어를 통해 수동으로만 가능하다.
```
SQL> alter index t_idx shrink space;
```
만약 아래와 같이 compact 옵션을 지정하면 공간은 반환하지 않으므로 coalesce와 같은 명령어가 된다.
```
SQL> alter index t_idx shrink space compact;
```
coalesce나 shrink는 레코드를 건건이 지웠다가 다시 입력하는 방식을 사용하므로 작업량이 많을 때는 rebuild 명령어를 사용하는 편이 나을 수 있다.
```
SQL> alter index t_idx rebuild;
SQL> alter idnex t_idx rebuild online;
```
위와 같은 방식으로 인덱스 구조를 슬림(slim)화하면 저장 효율이나 스캔 효율은 좋아지지만 일반적으로 인덱스 블록에는 어느 정도 공간을 남겨두는 것이 좋다.
인덱스 블록에 공간이 전혀 없으면 인덱스 분할이 자주 발생해 DML 성능을 떨어뜨리기 때문이다.
- Right-Growing 인덱스가 아닌 경우를 말한다. 맨 우측 리프 블록에만 값이 입력되는 Right-Growing 인덱스일 때는 pctfree를 0으로 설정하는 것이 좋다.

인덱스 분할 때문에 Shared 모드 enq: TX - index contention 대기 이벤트가 자주 나타난다면 pctfree를 높게 설정하는 것을 고려할 수 있다.
하지만 pctfree를 높게 설정하는 것만으로는 전혀 효과가 없다. 인덱스에서의 pctfree는 인덱스를 처음 생성하거나 rebuild할 때만 적용되기 때문이다.
따라서 인덱스 분할에 의한 경합을 줄이려면 pctfree를 높이고 나서 인덱스를 rebuild해야 한다.

하지만 그 효과는 일시적이다. 언젠가 빈 공간이 다시 채워지기 때문이며, 결국 적당한 시점마다 rebuild 작업을 반복하지 않는 한 근본적인 해결책이 되지는 못한다.

인덱스를 rebuild하는 데 걸리는 시간과 부하도 무시할 수 없다.
그나마 서비스다운타임(planned downtime)을 확보할 수 있는 상황이라면 적당한 pctfree 옵션과 함께 인덱스를 rebuild 해서 나쁠 거은 없지만, 24시간 가용성이 요구되는 시스템이라면 얘기가 다르다.
인덱스를 rebuild하는 동안 시스템에 주는 부하가 적지 않고, online rebuild 기능(coalesce, shrink 포함)을 이용하더라도 트랜잭션에 다소 경합을 일으키기 때문이다.

인덱스 스캔 효율 측면에서 보더라도, 대량의 delete 작업이 없으면 주기적으로 rebuild 하지 않더라도 그다지 나쁘지 않다.

따라서 아래와 같이 예상효과가 확실할 때만 인덱스 rebuild를 고려하는 것이 바람직하다.
- 인덱스 분할에 의한 경합이 현저히 높을 때
- 자주 사용되는 인덱스 스캔 효율을 높이고자 할 때, 특히 NL 조인에서 반복 액세스되는 인덱스 높이(height)가 증가했을 때
- 대량의 delete 작업을 수행한 이후 다시 레코드가 입력되기까지 오랜 시간이 소요될 때
- 총 레코드 수가 일정한데도 인덱스가 계속 커질 때

- ### [인덱스 freelist]

  테이블에서의 pctfree와 pctused는 각각 freelist에서 제외되는 시점과 다시 등록되는 시점을 지정하는 파라미터다.
  테이블은 Heap 방식으로 데이터를 입력하므로 매번 freelist를 참조해 데이터 삽입이 가능한 블록을 찾아야 한다.

  반면, 인덱스는 정렬된 구조로 자료를 삽입하므로 값이 입력될 때마다 freelist를 참조하지 않아도 된다.
  인덱스 구조를 탐색해 정렬 순서에 따라 정해진 곳에 레코드를 삽입하기 때문이며, 인덱스 freelist는 인덱스 분할로 빈 블록이 필요할 때만 참조한다.
  이처럼 테이블과 인덱스 간에 pctfree 의미와 작동방식이 서로 다르며, 인덱스에 pctused 파라미터가 없는 것도 특징적이다.

  #### [PCTFREE]
  테이블에서의 pctfree는 블록에 더 이상 insert가 발생하지 못하도록 freelist로부터 제외되는 시점을 지정하는 것이다. 그렇게 남겨진 빈 공간은 나중에 update를 위해 사용된다.

  인덱스에서의 pctfree는 용도가 다르다. 인덱스가 생성되는 시점에 공간을 꽉 채워두면 나중에 인덱스 분할이 빈번하게 발생하므로 이를 방지하려고 pctfree가 필요하다.
  이 옵션은 인덱스 최초 생성 또는 재생성 시점에만 적용되며, 지정한 비율만큼 공간을 남겨 두었다가 나중에 insert를 위해 사용된다.

  #### [PCTUSED]
  freelist에서 제거된 테이블 블록에 빈 공간이 일정 수준 이상 확보됐을 때만 다시 freelist에 등록되도록 하기 위해 pctused 파라미터가 필요하다.

  insert, delete가 자주 발생하는 테이블에 pctfree와 pctused 합이 100에 가깝다면 freelist 변경이 자주 발생하게 된다.
  예를 들어, pctfree가 10이고 pctused가 80이면 freelist에서 제거된 블록에 10% 정도 delete가 발생하는 순간 해당 블록을 다시 freelist에 등록해야 한다.

  반대로, delete가 적게 발생한다면 pctfree와 pctused를 100에 가깝도록 설정해야 테이블 블록 저장효율을 높일 수 있다.

  인덱스에는 pctused 파라미터가 아예 없다. 이유는, 인덱스에서 빈 공간은 항상 재사용 가능하기 때문이다. 예를 들어, 1부터 10까지의 값을 입력하면 인덱스에는 1부터 10까지의 값이 정렬된 채로 입력된다.
  이때 5를 지우고 commit한 후에 5를 다시 입력하면 앞서 지워진 그 공간을 남겨둘 하등 이유가 없다. 바로 그 곳에 삽입하면 된다.

  정리하면, 테이블에서의 freelist는 insert가 가능한 블록을 관리한다. [100-pctfree] 만큼의 공간이 차면 freelist에서 제거되고, pctused만큼만 남기고 레코드가 모두 지워질 때 다시
  freelist에 등록된다.

  인덱스에서의 freelist는 인덱스 분할에 사용 가능한 빈 블록들을 관리한다.
  기억할 점은, delete에 의해 비워진 인덱스 블록은 커밋 시점에 freelist에 반환되지만 insert 시점에 다시 값이 입력되더라도 곧바로 freelist에서 제거되지 않는다는 사실이다.
  freelist에 그대로 두었다가 인덱스 분할 때문에 freelist를 스캔하는 프로세스에 의해 정리된다.
  즉, freelist에서 얻은 블록이 비어있지 않으면 다른 블록을 재요청하기 전에 일단 해당 블록을 freelist에서 제거하는 방식이며, 이는 커밋 시점에 수행해야 할 일량을 최소화하기 위함이다.
  만약 값을 입력하고 커밋할 때마다 freelist를 관리해 주어야 한다면 'fast commit' 메커니즘에 문제가 생길지도 모른다.인