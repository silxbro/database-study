# 12. 기타 쿼리 변환

지금까지 설명한 것 외에도 이름이 밝혀지지 않은 많은 쿼리 변환이 작동하고 있다. 그 중 몇 가지 중요한 쿼리 변환만을 소개하고자 한다.

<br/>

## (1) 조인 컬럼에 IS NOT NULL 조건 추가
```
select count(e.empno), count(d.dname)
from   emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900
```
위와 같은 조인문을 처리할 때 조인 컬럼 deptno가 null인 데이터는 조인 액세스가 불필요하다. 어차피 조인에 실패하기 때문이다.
따라서 아래와 같이 필터 조건을 추가해 주면 불필요한 테이블 액세스 및 조인 시도를 줄일 수 있어 쿼리 성능 향상에 도움이 된다.
```
select count(e.empno), count(d.dname)
from   emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900
and    e.deptno is not null
and    d.deptno is not null
```
테스트를 위해 emp 테이블을 1,000번 복제한 t_emp 테이블을 만들어 보자.
```
create table t_emp
as
select *
from   scott.emp
     , (select rownum no from dual connect by level <= 1000);

alter table t_emp modify deptno null;  → CTAS 수행 결과, deptno가 not null일 때만 수행

update t_emp set deptno = null;

commit;

create index t_emp_idx on t_emp(sal);
```
14건을 갖는 emp 테이블을 1,000번 복제했으므로 총 건수는 14,000건이고, 모든 레코드의 deptno를 null 값으로 갱신했다.
아래 쿼리를 sal <= 2900 조건으로 드라이빙하려고 emp 테이블 sal 컬럼에 인덱스를 생성했고, 아직 테이블 및 컬럼 통계는 생성하지 않은 상태다.
```
select /*+ ordered use_nl(d) index(e t_emp_idx) index(d dept_pk) */
       count(e.empno), count(d.dname)
from   t_emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900

----------------------------------------------------------------------
| Id  | Operation                        | Name      | Rows  | Bytes |
----------------------------------------------------------------------
|   0 | SELECT STATEMENT                 |           |     1 |    50 |
|   1 |   SORT AGGREGATE                 |           |     1 |    50 |
|   2 |     NESTED LOOPS                 |           |     1 |    50 |
|   3 |       TABLE ACCESS BY INDEX ROWID| T_EMP     |  9165 |   349K|
|*  4 |         INDEX RANGE SCAN         | T_EMP_IDX |  9165 |       |
|   5 |       TABLE ACCESS BY INDEX ROWID| DEPT      |     1 |    11 |
|*  6 |         INDEX UNIQUE SCAN        | DEPT_PK   |     1 |       |
----------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  4 - access("SAL"<=2900)
  6 - access("D"."DEPTNO"="E"."DEPTNO")
```
위 Predicate 정보를 볼 때 아직 옵티마이저에 의해 추가된 필터 조건은 없다.

t_emp 테이블을 만든 원본 테이블 emp에는 sal <= 2900인 사원 레코드가 10개다. emp 테이블을 1,000번 복제했으므로 t_emp 테이블에는 sal <= 2900인 사원 레코드가 10,000개 존재할 것이다.
실제 수행해 보면, 아래와 같이 t_emp_idx 인덱스를 스캔하면서 10,000번의 테이블 액세스가 발생하는 것을 알 수 있다.
```
Rows     Row Source Operation
-------  ---------------------------------------------------------------------
      1  SORT AGGREGATE (cr=841 pr=0 pw=0 time=231035 us)
      0    NESTED LOOPS (cr=841 pr=0 pw=0 time=231014 us)
  10000      TABLE ACCESS BY INDEX ROWID T_EMP (cr=841 pr=0 pw=0 time=150041 us)
  10000        INDEX RANGE SCAN T_EMP_IDX (cr=22 pr=0 pw=0 time=30293 us)
      0      TABLE ACCESS BY INDEX ROWID DEPT (cr=0 pr=0 pw=0 time=185631 us)
      0        INDEX UNIQUE SCAN DEPT_PK (cr=0 pr=0 pw=0 time=74223 us)
```
여기서, t_emp 테이블에서 10,000개 레코드를 읽었지만 dept 테이블과의 조인 액세스가 전혀 발생하지 않은 것(cr=0)에 주목하자.
is null 조건을 따로 기술하지 않더라도 읽은 값이 null일 때는 조인 액세스를 하지 않는다는 뜻이며, 이는 매우 중요한 사실이 아닐 수 없다.
(만약 버퍼 Pinning 효과 때문이라면 적어도 dept_pk 인덱스를 두 번은 읽었을 것이다.)

이해할 수 없는 일이지만 Inner 테이블을 Full Table Scan으로 액세스할 때는 아래처럼 조인 액세스가 발생하며, 11g에서 테스트하더라도 마찬가지다.
(10,000번 탐색했으므로 한 번 액세스할 때마다 3개 블록씩 읽었다.)
```
select /*+ ordered use_nl(d) index(e t_emp_idx) full(d) */
       count(e.empno), count(d.dname)
from   t_emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900

Rows     Row Source Operation
-------  ---------------------------------------------------------------------
      1  SORT AGGREGATE (cr=30841 pr=0 pw=0 time=177677 us)
      0    NESTED LOOPS (cr=30841 pr=0 pw=0 time=177656 us)
  10000      TABLE ACCESS BY INDEX ROWID T_EMP (cr=841 pr=0 pw=0 time=150040 us)
  10000        INDEX RANGE SCAN T_EMP_IDX (cr=22 pr=0 pw=0 time=30301 us)
      0      TABLE ACCESS FULL DEPT (cr=30000 pr=0 pw=0 time=126322 us)
```
드라이빙 테이블에서 읽은 값이 null 일 때도 상황에 따라 조인 액세스가 일어날 수 있다는 뜻인데, 아예 e.deptno is not null 조건을 명시적으로 추가해 준다면 염려할 필요가 없다.

다행히, 컬럼 통계를 수집하고 나면 옵티마이저가 그런 조건절을 자동으로 추가해 준다. 단, 조인 컬럼의 null 값 비중이 5% 이상일 때만 이 기능이 작동한다. 아래와 같이 통계정보를 생성하고 다시 수행해 보자.
```
begin
  dmbs_stats.gather_table_stats(user, 't_emp')
        , method_opt => 'for all columns', no_invalidate=>false);
end;
/

select /*+ ordered use_nl(d) index(e t_emp_idx) full(d) */
       count(e.empno), count(d.dname)
from   t_emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900

Rows     Row Source Operation
-------  ---------------------------------------------------------------------
      1  SORT AGGREGATE (cr=841 pr=0 pw=0 time=7836 us)
      0    NESTED LOOPS (cr=841 pr=0 pw=0 time=7815 us)
      0      TABLE ACCESS BY INDEX ROWID T_EMP (cr=841 pr=0 pw=0 time=7803 us)
  10000        INDEX RANGE SCAN T_EMP_IDX (cr=22 pr=0 pw=0 time=30305 us)
      0      TABLE ACCESS FULL DEPT (cr=0 pr=0 pw=0 time=0 us)
```
dept 테이블을 10,000번 Full Scan하면서 발생하던 30,000개의 블록 I/O가 사라졌다.
예상 실행계획과 함께 출력되는 Predicate 정보를 보면 옵티마이저에 의해 e.depnto is not null 조건이 추가되었음을 알 수 있다.
```
Predicate Information (identified by operation id) :
----------------------------------------------------
  3 - filter("E"."DEPTNO" IS NOT NULL)
  4 - access("SAL"<=2900)
  5 - filter("D"."DEPTNO"="E"."DEPTNO")
```
t_emp 테이블을 액세스하면서 발생한 블록 I/O는 통계정보를 수집하기 전과 똑같이 841개다. 추가된 is not null 조건을 필터링하려면 어차피 테이블을 방문해야 하기 때문이다.

아래와 같이 t_emp_idx 인덱스에 deptno 컬럼을 추가하고 다시 수행하면 블록 I/O가 841에서 23으로 확연히 준다.
```
drop index t_emp_idx;

create index t_emp_idx on t_emp(sal, deptno);

select /*+ ordered use_nl(d) index(e t_emp_idx) */
       count(e.empno), count(d.dname)
from   t_emp e, dept d
where  d.deptno = e.deptno
and    e.sal <= 2900

Rows     Row Source Operation
-------  ---------------------------------------------------------------------
      0  STATEMENT
      1    SORT AGGREGATE (cr=23 pr=0 pw=0 time=3932 us)
      0      NESTED LOOPS (cr=23 pr=0 pw=0 time=3896 us)
      0        TABLE ACCESS BY INDEX ROWID T_EMP (cr=23 pr=0 pw=0 time=3878 us)
      0          INDEX RANGE SCAN T_EMP_IDX (cr=23 pr=0 pw=0 time=3858 us)
      0        TABLE ACCESS FULL DEPT (cr=0 pr=0 pw=0 time=0 us)
```
이처럼 조인 컬럼에 is not null 조건을 추가해 주면 NL 조인뿐만 아니라 해시 조인, 소트 머지 조인 시에도 효과를 발휘한다.
우선, 해시 조인을 위해 Build Input을 읽어 해시 맵을 만들 때 더 적은 메모리를 사용한다. Probe Input을 읽을 때도 null 값인 레코드를 제외함으로써 해시 맵 탐색 횟수를 줄일 수 있다.
양쪽 모두 null 값 비중이 클수록 효과도 커진다.

소트 머지 조인할 때도 양쪽 테이블에서 조인 컬럼이 null인 레코드를 제외한다면 소트 및 비교 연산 횟수를 줄일 수 있다.

이런 여러 가지 사실에 비추어 볼 때, 조인 컬럼에 대한 is not null 조건을 추가한다고 손해 볼 일은 전혀 없다. 그런데도 옵티마이저는 null 값 비중이 5%를 넘을 때만 이런 쿼리 변환을 시행한다.
따라서 필요하다면 옵티마이저 기능에 의존하지 말고 사용자가 직접 위와 같은 조건을 추가해 줌으로써 불필요한 액세스를 줄일 수 있다.

그리고 조인 컬럼에 null 값 비중에 많을 때 임의의 Default 값(0, 'x'등)으로 채우는 방식으로 설계하면 조인 성능을 떨어뜨릴 수 있다는 사실도 기억하기 바란다.

<br/>

## (2) 필터 조건 추가
아래와 같이 바인드 변수로 between 검색하는 쿼리가 있다고 하자. 쿼리를 수행할 때 사용자가 :mx보다 :mn 변수에 더 큰 값을 입력한다면 쿼리 결과는 공집합이다.
```
select * from emp
where  sal between :mn and :mx
```
사전에 두 값을 비교해 알 수 있음에도 쿼리를 실제 수행하고서야 공집합을 출력한다면 매우 비합리적이다. 잦은 일은 아니겠지만 초대용량 테이블을 조회하면서 사용자가 값을 거꾸로 입력하는 경우를 상상해 보라.

그럴 경우 8i까지는 사용자가 한참을 기다려야만 했다. 9i부터는 이를 방지하기 위해 옵티마이저가 임의로 필터 조건식을 추가한다.
아래 실행계획에서 1번 오퍼레이션 단계에 사용된 Filter Predicate 정보를 확인하기 바란다.
```
--------------------------------------------------------------------
| Id  | Operation              | Name      | Rows  | Bytes | Cost  |
--------------------------------------------------------------------
|   0 | SELECT STATEMENT       |           |     1 |    32 |     2 |
|*  1 |   FILTER               |           |       |       |       |
|*  2 |     TABLE ACCESS FULL  | EMP       |     1 |    32 |     2 |
--------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  1 - filter(TO_NUMBER(:MN)<=TO_NUMBER(:MX))
  2 - filter("EMP"."SAL">=TO_NUMBER(:MN) AND "EMP"."SAL"<=TO_NUMBER(:MX))
```
아래는 :mn에 5000, :mx에 100을 입력하고 실제 수행했을 때의 결과인데, 블록 I/O가 전혀 발생하지 않은 것을 볼 수 있다.
```
Statistics
-----------------------------------------------------------------
         0  recursive calls
         0  db block gets
         0  consistent gets
         0  physical reads
      ..    .....
```
실행계획 상으로는 Table Full Scan을 수행하고 나서 필터 처리가 일어나는 것 같지만 실제로는 Table Full Scan 자체를 생략한 것이다.

바인드 변수 대신 상수 값으로 조회할 때도 filter 조건이 추가되는데, 아래와 같은 9i와 10g에서 조금 다르게 처리하고 있다.
- 9i : filter(5000<=100)
- 10g 이상 : filter(NULL IS NOT NULL)

9i에서 오브젝트 통계가 없으면 RBO 모드로 작동해 위와 같은 쿼리 변환이 일어나지 않는다.
10g는 통계정보가 없어도 항상 CBO 모드로 작동하므로 쿼리 변환이 잘 일어나지만 optimizer_features_enable 파라미터를 8.1.7로 바꾸고 테스트해 보면 아래와 같이 불필요한 I/O를 수행한다.
```
alter session set optimizer_features_enable = '8.1.7';

select * from emp
where  sal between :mn and :mx

--------------------------------------------------------------------
| Id  | Operation              | Name      | Rows  | Bytes | Cost  |
--------------------------------------------------------------------
|   0 | SELECT STATEMENT       |           |       |       |       |
|*  1 |   TABLE ACCESS FULL    | EMP       |       |       |       |
--------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  1 - filter("SAL">=TO_NUMBER(:MN) AND "SAL"<=TO_NUMBER(:MX))

Statistics
-----------------------------------------------------------------
         0  recursive calls
         0  db block gets
         3  consistent gets
         0  physical reads
      ..    .....
```

<br/>

## (3) 조건절 비교 순서
아래와 같은 조건절을 처리할 때 부등호(>) 조건을 먼저 평가하느냐 like 조건을 먼저 평가하느냐에 따라 일량에 차이가 생긴다.
```
select /*+ full(도서) */ 도서번호, 도서명, 가격, 저자, 출판사, isbn
from   도서
where  도서명 > :last_book_nm
and    도서명 like :book_nm || '%'
```
이에 옵티마이저는, 테이블 전체를 스캔하거나 인덱스를 수평적으로 스캔할 때의 Filter 조건식(Filter Predicates)을 평가할 때 선택도가 낮은 컬럼을 먼저 처리하도록 순서를 조정한다
(인덱스 수직적 탐색을 위한 조건절에는 영향 없음).

이런 쿼리 변환이 작동하려면 9i, 10g를 불문하고 옵티마이저에게 시스템 통계를 제공함으로써 CPU Costing 모델을 활성화해야 한다.
I/O Costing 모델에서는 where절에 기술된 순서대로 조건식 비교가 일어난다. RBO 모드에서는 where절에 기술된 반대 순서로 조건식 비교가 일어난다. 정리하면 아래 표와 같다.

|옵티마이저 모드|조건절 비교 순서|
|:---|:---|
|RBO|where절이 기술된 반대 순서로|
|CBO (I/O Costing 모드)|where절에 기술된 순서대로|
|CBO (CPU Costing 모드)|비교 연산해야 할 일량을 고려해 옵티마이저가 결정.<br/>선택도가 낮은 조건식부터 평가|

테스트를 위해 아래와 같이 t 테이블을 생성하고, 통계정보를 생성하였다. 10g 환경이 기본적으로 CPU Costing 모드가 활성화된 상태다.
```
SQL> create table t
  2  nologgin
  3  as
  4  select 1 a, rownum b from dual connect by level <= 1000000 ;

SQL> exec dbms_stats.gather_table_stats(user, 't', no_invalidate => false);
```
아래와 같이 a와 b 컬럼에 대한 조건식을 서로 바꿔 가면서 테스트 해 보았지만 선택도가 낮은 컬럼이 항상 먼저 처리되는 것을 볼 수 있다.
```
SQL> set autotrace traceonly exp
SQL> select * from t
  2  where  a = 1
  3  and    b = 1000;

----------------------------------------------------------------------------
| Id  | Operation          | Name | Rows  | Bytes | Cost  (%CPU)| Time     |
----------------------------------------------------------------------------
|   0 | SELECT STATEMENT   |      |     1 |     6 |    433   (7)| 00:00:06 |
|*  1 |   TABLE ACCESS FULL| T    |     1 |     6 |    433   (7)| 00:00:06 |
----------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  1 - filter("B"=1000 AND "A"=1)

SQL> select * from t
  2  where  b = 1000
  3  and    a = 1;

----------------------------------------------------------------------------
| Id  | Operation          | Name | Rows  | Bytes | Cost  (%CPU)| Time     |
----------------------------------------------------------------------------
|   0 | SELECT STATEMENT   |      |     1 |     6 |    433   (7)| 00:00:06 |
|*  1 |   TABLE ACCESS FULL| T    |     1 |     6 |    433   (7)| 00:00:06 |
----------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  1 - filter("B"=1000 AND "A"=1)
```
아래와 같이 ordered_predicates 힌트를 사용하면 CPU Costing 모드에서도 조건절 비교 순서를 제어할 수 있다. 이 힌트를 사용하면 where절에 기술된 순서대로 비교가 일어난다.
옵티마이저의 판단을 무시하고 아래와 같이 힌트를 썼더니 예상 비용이 433에서 440으로 증가한 사실에 주목하기 바란다. I/O뿐만 아니라 CPU 연산 시간까지 비용 계산식에 포함하고 있음을 알 수 있다.
```
SQL> select /*+ ORDERED_PREDICATES */ * from t
  2  where  a = 1
  3  and    b = 1000 ;

----------------------------------------------------------------------------
| Id  | Operation          | Name | Rows  | Bytes | Cost  (%CPU)| Time     |
----------------------------------------------------------------------------
|   0 | SELECT STATEMENT   |      |     1 |     6 |    440   (9)| 00:00:06 |
|*  1 |   TABLE ACCESS FULL| T    |     1 |     6 |    440   (9)| 00:00:06 |
----------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  1 - filter("A"=1 AND "B"=1000)
```
아래와 같이 9i에서 시스템 통계를 지우거나 10g에서 I/O 비용 모델로 전환한 상태에서 같은 테스트를 수행해 보면, where절에 기술된 순서대로 조건 비교가 일어난다.
```
SQL> exec dbms_stats.delete_system_stats;             -- 9i일 때
SQL> alter session set "_optimizer_cost_model" = io;  -- 10g일 때
```
아래와 같이 RBO 모드로 바꾼 상태에서 테스트해 보면, where절에 기술된 반대 순서로 조건 비교가 일어난다.
```
SQL> alter session set optimizer_mode = rule;
```

### [ordered_predicates 힌트의 또 다른 용도]
10g에서 OR 또는 IN-List 조건에 대한 OR-Expansion이 일어날 때 실행 순서를 제어할 목적으로 ordered_predicates 힌트를 사용할 수도 있다.
예를 들어, 9i까지는 I/O 비용 모델, CPU 비용 모델을 불문하고 IN-List를 OR-Expansion(=Concatenation) 방식으로 처리할 때 뒤쪽에 있는 값을 먼저 실행한다.
하지만 10g CPU 비용 모델 하에서는 계산된 카디널리티가 낮은 쪽을 먼저 실행한다.

실제 그런지 10g에서 테스트해 보자. 이전에 설명한 것처럼 10g에서 같은 컬럼에 대한 OR 또는 IN-List 조건에 OR-Expansion이 작동하도록 하려면 use_concat 힌트에 아래와 같은 인자를 사용해야 한다.
```
SQL> set autotrace traceonly exp
SQL> select /*+ use_concat(@subq 1) qb_name(subq) index(e) */ *
  2  from   emp e
  3  where  deptno in (10,30)  ;

-----------------------------------------------------------------------------------
| Id  | Operation                      | Name        | Rows  | Bytes | Cost (%CPU)|
-----------------------------------------------------------------------------------
|   0 | SELECT STATEMENT               |             |     9 |   333 |     4   (0)|
|   1 |   CONCATENATION                |             |       |       |            |
|   2 |     TABLE ACCESS BY INDEX ROWID| EMP         |     3 |   111 |     2   (0)|
|*  3 |       INDEX RANGE SCAN         | EMP_DEPTNO_I|     3 |       |     1   (0)|
|   4 |     TABLE ACCESS BY INDEX ROWID| EMP         |     6 |   222 |     2   (0)|
|*  5 |       INDEX RANGE SCAN         | EMP_DEPTNO_I|     6 |       |     1   (0)|
-----------------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  3 - access("DEPTNO"=10)
  5 - access("DEPTNO"=30)
```
30을 IN-List 뒤쪽에 기술했음에도, Predicate 정보를 보면 통계정보 상 카디널리티가 낮은 10이 위쪽으로 올라가는 것을 볼 수 있다. 실제 수행해 봐도 10이 먼저 출력된다.

아래와 같이 ordered_predicates 힌트를 사용하면 9i 이전 버전처럼 IN-List 뒤쪽에 있는 값을 먼저 실행한다.
```
SQL> select /*+ use_concat(@subq 1) qb_name(subq) index(e) ordered_predicates */ *
  2  from   emp e
  3  where  deptno in (10,30)  ;

-----------------------------------------------------------------------------------
| Id  | Operation                      | Name        | Rows  | Bytes | Cost (%CPU)|
-----------------------------------------------------------------------------------
|   0 | SELECT STATEMENT               |             |     9 |   333 |     4   (0)|
|   1 |   CONCATENATION                |             |       |       |            |
|   2 |     TABLE ACCESS BY INDEX ROWID| EMP         |     6 |   222 |     2   (0)|
|*  3 |       INDEX RANGE SCAN         | EMP_DEPTNO_I|     6 |       |     1   (0)|
|   4 |     TABLE ACCESS BY INDEX ROWID| EMP         |     3 |   111 |     2   (0)|
|*  5 |       INDEX RANGE SCAN         | EMP_DEPTNO_I|     3 |       |     1   (0)|
-----------------------------------------------------------------------------------

Predicate Information (identified by operation id) :
----------------------------------------------------
  3 - access("DEPTNO"=30)
  5 - access("DEPTNO"=10)
```
또는 _optimizer_cost_model 파라미터를 'IO'로 설정하거나 아래와 같이 no_cpu_costing 힌트를 사용해 IO 비용 모델로 변경해도 IN-List 뒤쪽부터 실행한다.
```
SQL> select /*+ use_concat(@subq 1) qb_name(subq) index(e) no_cpu_costing */ *
  2  from   emp e
  3  where  deptno in (10,30)  ;
```