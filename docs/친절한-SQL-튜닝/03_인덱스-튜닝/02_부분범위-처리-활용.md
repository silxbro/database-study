# 3.2 | 부분범위 처리 활용
테이블 랜덤 액세스가 성능에 미치는 영향, 그리고 그것을 최소화하기 위해 인덱스에 컬럼을 추가하고 테이블 저장 구조를 개선하는 방법을 살펴봤다.

본 절은 테이블 랜덤 액세스로 인한 인덱스 손익분기점의 한계를 극복할 히든카드를 추가로 소개한다.
부분범위 처리 원리가 바로 그것인데, 이를 활용하면 인덱스로 액세스할 대상 레코드가 아무리 많아도 아주 빠른 응답속도를 낼 수 있다.
원리를 모른 상태에서 경험하면 마법이라고 느낄 만큼 극적인 성능 향상 효과를 가져다주는 부분범위 처리에 어떤 원리가 숨어있는지 지금부터 살펴보자.

<br/>

## (1) 부분범위 처리
DBMS가 클라이언트에게 데이터를 전송할 때 일정량씩 나누어 전송한다.
전체 결과집합 중 아직 전송하지 않은 분량이 많이 남아있어도 서버 프로세스는 클라이언트로부터 추가 Fetch Call을 받기 전까지 그대로 멈춰 서서 기다린다.

OLTP 환경에서 대용량 데이터를 빠르게 핸들링할 수 있는 아주 중요한 원리가 바로 여기에 숨어있다.
예를 들어, 마우스로 클릭하면 아래 JAVA 메소드를 호출하는 실행 버튼이 있다고 하자.
SQL문에 사용한 BIG_TABLE이 1억 건에 이르는 대용량 테이블이어도 실행 결과는 버튼을 클릭하자마자 곧바로 화면에 출력된다.
```
private void execute(Connection con) throws Exception {
  Statement stmt = con.createStatement();
  ResultSet rs = stmt.executeQuery("select name from big_table");

  for (int i=0; i<100; i++) {
    if (rs.next()) System.out.println(rs.getString());
  }

  rs.close();
  stmt.close();
}
```
1억 건짜리 테이블인데도 결과를 빨리 출력할 수 있는 이유는, DBMS가 데이터를 모두 읽어 한 번에 전송하지 않고 먼저 읽는 데이터부터 일정량(Array Size)을 전송하고 멈추기 때문이다.
데이터를 전송하고 나면 서버 프로세스는 CPU를 OS에 반환하고 대기 큐에서 잠을 잔다. 다음 Fetch Call을 받으면 대기 큐에서 나와 그다음 데이터부터 일정량을 읽어서 전송하고 또다시 잠을 잔다.

이처럼 전체 쿼리 결과집합을 쉼 없이 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어 전송하는 것을 이른바 '부분범위 처리'라고 한다.

데이터를 전송하는 단위인 Array Size는 클라이언트 프로그램에서 설정한다. JAVA에서 Array Size 기본값은 10이며, Statement 객체 setFetchSize 메소드를 통해 설정을 변경할 수 있다.
Array Size가 10인 상태에서 위 JAVA 프로그램이 데이터를 읽어 들이는 메커니즘은 아래와 같다.
- [1] 최초 rs.next() 호출 시 Fetch Call을 통해 DB 서버로부터 전송받은 데이터 10건을 클라이언트 캐시에 저장한다.
- [2] 이후 rs.next() 호출할 때는 Fetch Call을 발생시키지 않고 캐시에서 데이터를 읽는다.
- [3] 캐시에 저장한 데이터를 모두 소진한 상태에서 rs.next() 호출 시 추가 Fetch Call을 통해 10건을 전송받는다.
- [4] 100건을 다 읽을 때까지 2 ~ 3번 과정을 반복한다.

100개 레코드를 전송받아 콘솔에 출력(내부적으로 연속해서 10번의 Fetch Call 발생)하고는 곧바로 ResultSet과 Statement 객체를 닫았으므로 위 JAVA 프로그램은 BIG_TABLE에 데이터가 아무리
많아도 오래 걸릴 이유가 없다.

### [정렬 조건이 있을 때 부분범위 처리]
만약 쿼리문에 아래와 같이 order by를 추가하면 어떻게 될까? 이때도 부분범위 처리가 작동할까?
```
Statement stmt = con.createStatement();
ResultSet rs = stmt.executeQuery("select name from big_table order by created");
```
DB 서버는 '모든' 데이터를 다 읽어 created 순으로 정렬을 마치고서야 클라이언트에게 데이터 전송을 시작할 수 있다. 전체범위처리다.
Sort Area와 Temp 테이블스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에게 데이터를 전송한다.

다행히 created 컬럼이 선두인 인덱스가 있으면, 부분범위 처리가 가능하다. 인덱스는 항상 정렬된 상태를 유지하므로 전체 데이터를 정렬하지 않고도 정렬된 상태의 결과집합을 바로 전송할 수 있기 때문이다.

### [Array Size 조정을 통한 Fetch Call 최소화]
부분범위 처리 원리를 이해했다면, 네트워크를 통해 전송해야 할 데이터량에 따라 Array Size를 조절할 필요가 있음을 직감했을 것이다.
예를 들어, 대량 데이터를 파일로 내려받는다면 어차피 데이터를 모두 전송해야 하므로 가급적 그 값을 크게 설정해야 한다.
Array Size를 조정한다고 해서 전송해야 할 총량이 변하진 않지만, Fetch Call 횟수를 그만큼 줄일 수 있다.

반대로, 앞쪽 일부 데이터만 Fetch하다가 멈추는 프로그램이라면 Array Size를 작게 설정하는 것이 유리하다. 불필요하게 많은 데이터를 전송하고 버리는 비효율을 줄일 수 있기 때문이다.
방금 본 JAVA 프로그램에서 만약 Array Size를 1,000으로 설정한다면, 사용하지도 않고 버릴 뒤쪽 900개 레코드를 읽어서 전송하는 과정에 네트워크와 서버, 클라이언트 자원만 낭비하게 된다.

### [쿼리 툴에서 부분범위 처리]
이번에는 토드나 오렌지 같은 쿼리 툴에서 부분범위 처리가 어떻게 작동하는지 확인해 보자.

오렌지에 설정된 옵션(Tool>> Orange Options)을 보면 Array Size의 설정값을 알 수 있다. 이는 서버에 Fetch Call할 때 요청하는 데이터의 개수가 설정되어 있는 것이다.
Initial Fetch는 쿼리를 처음 수행할 때 출력되는 데이터의 개수이다.
- 예를 들어, Initial Fetch, Array Size가 각각 100, 20으로 설정돼 있을 때 오렌지는 쿼리를 수행하자마자 화면에 100개 레코드가 출력된 상태에서 사용자가 101번째 레코드를 읽으려고
  스크롤하는 순간, 추가 Fetch Call이 발생한다. 이때부터는 20개씩 출력한다.

이번에는 오라클 기본 쿼리 툴 SQL*Plus에서 같은 테스트를 해 보자. 쿼리를 수행해보면 중간에 멈추지 않고 데이터를 계속 출력한다. 부분범위 처리가 작동하지 않는 듯하다.
같은 DB 서버에 접속했는데, 어떤 쿼리 툴에서는 부분범위 처리가 작동하고 어떤 쿼리 툴에서는 작동하지 않는 이유가 무엇일까?
참고로, MS-SQL Server 사용자가 주로 사용하는 쿼리 분석기(Query Analyzer)에서도 쿼리를 수행해 보면, 멈추지 않고 전체 데이터를 출력한다.

모든 DBMS는 데이터를 조금씩 나눠서 전송한다. 즉, 부분범위 처리 방식으로 결과집합을 전송한다.
이 특징을 이용해 중간에 멈췄다가 사용자의 추가 요청이 있을 때마다 데이터를 가져오도록 구현하고 안 하고는 클라이언트 프로그램을 개발하는 개발자의 몫이다.
오라클 사용자가 주로 사용하는 토드나 오렌지 같은 쿼리 툴 개발자는 부분범위 처리 원리를 이용하는 방식으로 구현했지만, 오라클 SQL*Plus와 SQL Server 쿼리 분석기 개발자는 그렇게 구현하지 않았다.

<br/>

## (2) 부분범위 처리 구현
실제 구현 예시를 보자. 아래 JAVA 소스는 부분범위 처리를 활용하지 않은 예시다. 대개 우리는 이처럼 쉽고 단순한 방식으로 코딩한다.
```
public class AllRange {

  public static void execute(Connection con) throws Exception {
    int arraysize = 10;
    String SQLStmt = "select object_id, object_name, from all_objects";
    Statement stmt = con.createStatement();
    stmt.setFetchSize(arraysize);
    ResultSet rs = stmt.executeQuery(SQLStmt);
    while (rs.next()) {
      System.out.println(rs.getLong(1) + " : " + rs.getString(2));
    }
    rs.close();
    stmt.close();
  }

  public static void main(String[] args) throws Exception {

    Connection con = getConnection();

    execute(con);

    releaseConnection(con);
  }
}
```

아래 JAVA 소스는 부분범위 처리를 활용한 코딩 예시다. 출력 레코드 수가 Array Size에 도달하면 멈추었다가 사용자 요청이 있을 때 다시 데이터를 Fetch하는 부분이 핵심이다.
개발자가 일일이 이렇게 구현할 순 없고, 개발 프레임워크에 미리 구현해 있는 기능을 활용한다.
```
import java.io.*;
import java.lang.*;
import java.util.*;
import java.net.*;
import java.sql.*;
import oracle.jdbc.driver.*;

public class PartialRange {

  public static int fetch(ResultSet rs, int arraysize) throws Exception {
    int i = 0;
    while (rs.next()) {
      System.out.println(rs.getLong(1) + " : " + rs.getString(2));
      if (++i >= arraysize) return i;
    }
    return i;
  }

  public static void execute(Connection con) throws Exception {
    int arraysize = 10;
    String SQLStmt = "select object_id, object_name from all_objects";
    Statement stmt = con.createStatement();
    stmt.setFetchSize(arraysize);
    ResultSet rs = stmt.executeQuery(SQLStmt);
    while (true) {
      int r = fetch(rs, arraysize);
      if (r < arraysize) break;
      System.out.println("Enter to Continue ... (Q)uit? ");
      BufferedReader in = new BufferedReader(new InputStreamReader(System.in));
      String input = in.readLine();
      if (input.equals("Q")) break;
    }
    rs.close();
    stmt.close();
  }

  public static void main(String[] args) throws Exception {

    Connection con = getConnection();

    execute(con);

    releaseConnection(con);
  }
}
```

<br/>

## (3) OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
**OLTP**는 'Online Transaction Processing'의 줄임말이다. OLTP 시스템은 말 그대로 온라인 트랜잭션을 처리하는 시스템을 말한다. 온라인 트랜잭션은 일반적으로 **소량** 데이터를 읽고 갱신한다.

그런데 OLTP 시스템이라고 항상 소량 데이터만 조회하는 것은 아니다. 수천수만 건을 조회하는 경우도 있다. 인덱스를 이용해 수천수만 건을 조회하려면 만족할만한 성능을 내기 어려울 수 있다.
많은 테이블 랜덤 액세스가 발생하기 때문이다. 다행히(=우연히) 버퍼캐시히트율이 좋다면 빠른 성능을 보일 수도 있지만, 그렇지 않다면 수십 초간 기다려야 할 수도 있다.

다행히 OLTP성 업무에서 쿼리 결과 집합이 아주 많을 때 사용자가 모든 데이터를 일일이 다 확인하지는 않는다. 특정한 정렬 순서로 상위 일부 데이터만 확인한다.
은행계좌 입출금 조회, 뉴스 또는 게시판(BBS) 조회 등이 여기에 해당하며, 주로 목록을 조회하는 경우다.
그럴 때, 항상 정렬 상태를 유지하는 인덱스를 이용하면, 정렬 작업을 생략하고 앞쪽 일부 데이터를 아주 빠르게 보여줄 수 있다.

인덱스와 부분범위 처리 원리를 잘 활용하면 OLTP 환경에서 극적인 성능개선 효과를 얻을 수 있는 원리가 바로 여기에 숨어 있다. 아래 쿼리를 예로 들어보자.
```
select 게시글ID, 제목, 작성자, 등록일시
from   게시판
where  게시판구분코드 = 'A'
order by 등록일시 desc
```
인덱스 선두 컬럼을 [게시판구분코드 + 등록일시] 순으로 구성하지 않으면(게시판구분코드 단일 컬럼으로 구성하거나, 게시판구분코드 바로 뒤에 등록일시가 위치하지 않으면),
소트 연산을 생략할 수 없다. 게시판구분코드 = 'A' 조건을 만족하는 모든 레코드를 인덱스에서 읽어야 하고, 그만큼 많은 테이블 랜덤 액세스가 발생한다.
모든 데이터를 다 읽어 등록일시 역순으로 정렬을 마치고서야 출력을 시작하므로 OLTP 환경에서 요구되는 빠른 응답 속도를 내기 어렵다. 아래는 인덱스로 소트 연산을 생략할 수 없을 때 나타나는 실행계획이다.
```
--------------------------------------------------------------------------------------
| Id  | Operation                           | Name     | Rows  | Bytes  | Cost (%CPU)|
--------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT                    |          | 400000 |  3515K|  2041   (1)|
|   1 |   SORT ORDER BY                     |          | 400000 |  3515K|  2041   (1)|
|   2 |     TABLE ACCESS BY INDEX ROWID     | 게시판     | 400000 |  3515K|  1210   (1)|
|*  3 |       INDEX RANGE SCAN              | 게시판_X01 | 400000 |       |    96   (2)|
--------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
  2 - access("게시판구분코드"='A')
```

인덱스를 [게시판구분코드 + 등록일시] 순으로 구성하면 Sort Order By 연산을 생략할 수 있다. 아래는 [게시판구분코드 + 등록일시] 순으로 구성된 인덱스를 사용할 때의 실행계획이다.
SQL 문에 Order By절이 있음에도 불구하고 Sort Order By 오퍼레이션이 자동으로 제거된 것을 확인하기 바란다.
```
------------------------------------------------------------------------------------
| Id  | Operation                         | Name     | Rows  | Bytes  | Cost (%CPU)|
------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT                  |          | 400000 |  3515K|  1372   (1)|
|   1 |     TABLE ACCESS BY INDEX ROWID   | 게시판     | 400000 |  3515K|  1372   (1)|
|*  2 |       INDEX RANGE SCAN DESCENDING | 게시판_X02 | 400000 |       |   258   (1)|
------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
  2 - access("게시판구분코드"='A')
```
이 방식으로 수행하면 게시판구분코드 = 'A' 조건을 만족하는 전체 로우를 읽지 않고도 바로 결과집합 출력을 시작할 수 있다.

### [멈출 수 있어야 의미있는 부분범위 처리]
문제는 앞쪽 일부만 출력하고 멈출 수 있는가이다. 이것이 부분범위 처리의 핵심이다. 토드나 오렌지 같은 쿼리 툴은 이미 그렇게 구현돼 있다.
이들처럼 클라이언트 프로그램이 DB 서버에 직접 접속하는 2-Tier 환경에서는 그렇게 구현할 수 있었고, 실제로도 그렇게 많이 구현했었다.

그런데 클라이언트와 DB 서버 사이에 WAS, AP 서버 등이 존재하는 n-Tier 아키텍처에서는 클라이언트가 특정 DB 커넥션을 독점할 수 없다.
단위 작업을 마치면 DB 커넥션을 곧바로 커넥션 풀에 반환해야 하므로 그 전에 SQL 조회 결과를 클라이언트에게 '모두' 전송하고 커서(Cursor)를 닫아야 한다.
따라서 SQL 결과집합을 조금씩 나눠 전송하도록 구현하기 어렵다.
- JAVA 기준으로 Statement와 ResultSet 객체. 마이크로소프트 ADODB 기준으로 Command와 Recordset 객체가 커서 역할을 한다.
  참고로, 여기서 말하는 커서는 '애플리케이션 커서'를 의미한다. 라이브러리 캐시의 '공유 커서(Shared SQL Area)', PGA의 '세션 커서(Private SQL Area)'와 헷갈리지 않기 바란다.

그렇다면 부분범위 처리는 n-Tier 환경에서 의미 없는 개념일까? 그렇지 않다. 부분범위 처리는 n-Tier 환경에서도 여전히 유효하다.

- #### [배치 I/O]

  인덱스 ROWID를 이용한 테이블 랜덤 액세스는 고비용 구조다. 인덱스를 이용해 대량 데이터를 조회하면, 디스크 I/O 발생량도 함께 증가하므로 성능이 급격히 나빠진다.
  다행히 부분범위 처리 원리를 활용해 상위 N개 집합을 빠르게 출력하도록 구현할 수 있다면, 인덱스로 액세스할 전체 대상 레코드가 아무리 많아도 빠른 응답속도를 낼 수 있다.
  그러기 위해선 인덱스를 이용해 소트 연산을 생략할 수 있어야 하는데, 이와 관련해서 꼭 기억해야 할 내용이 있어 소개한다.

  디스크 랜덤 I/O 성능을 높이려고 DBMS 업체들이 계속 노력을 기울이는 가운데, 오라클에서 최근 가장 눈에 띄는 개선은 배치 I/O 기능에서 볼 수 있다.
  배치(Batch) I/O는 읽는 블록마다 건건이 I/O Call을 발생시키는 비효율을 줄이기 위해 고안한 기능이다.
  인덱스를 이용해 테이블을 액세스하다가 버퍼 캐시에서 블록을 찾지 못하면 일반적으로 디스크 블록을 바로 읽는데, 이 기능이 작동하면 테이블 블록에 대한 디스크 I/O Call을 미뤘다가 읽을 블록이
  일정량 쌓이면 한꺼번에 처리한다.

  11g에서는 NL 조인 Inner 쪽 테이블 액세스할 때만 이 기능이 작동했지만, 12c부터는 인덱스 ROWID로 테이블을 액세스하는 어떤 부분에서든 이 기능이 작동할 수 있다.

  - #### [데이터 정렬 이슈]

    배치 I/O 기능이 작동하면 인덱스를 이용해서 출력하는 데이터 정렬 순서가 매번 다를 수 있다는 사실에 주목해야 한다.
    테이블 블록을 모두 버퍼 캐시에서 찾을 때는(버퍼캐시히트율 = 100%) 기존처럼 인덱스 키값 순으로 데이터가 출력되지만, 그렇지 않을 때(버퍼캐시히트율 < 100%)
    즉, 실제 배치 I/O가 작동할 때는 데이터 출력 순서가 인덱스 정렬 순서와 다를 수 있다.

    실제 SQL과 실행계획을 보면서 확인해 보자. 아래는 인덱스를 이용해 소트 연산을 생략할 수 있는 경우다. SQL에 ORDER BY 절이 있음에도 불구하고 실행계획에 SORT ORDER BY 오퍼레이션이 생략되었다.

    ```
    SQL> create index emp_x01 on emp(deptno, job, empno);

    SQL> set autotrace traceonly exp;

    SQL> select * from emp e where deptno = 20 order by job, empno;

    -----------------------------------------------------------------------------
    | Id  | Operation                         | Name    | Rows  | Bytes | Cost  |
    -----------------------------------------------------------------------------
    |   0 | SELECT STATEMENT                  |         |     5 |   190 |     2 |
    |   1 |     TABLE ACCESS BY INDEX ROWID   | EMP     |     5 |   190 |     2 |
    |   2 |       INDEX RANGE SCAN            | EMP_X01 |     5 |       |     1 |
    -----------------------------------------------------------------------------
    ```
    이번에는 12c 버전에서 batch_table_access_by_rowid 힌트를 사용해 보자.
    배치 I/O가 작동할 수 있다는 사실을 표현하기 위해 아래와 같이 테이블 액세스 단계(ID=2) 뒤쪽에 'BATCHED'가 추가됐고, 동시에 SORT ORDER BY 오퍼레이션(ID=1)도 추가됐다.
    소트 생략 가능한 인덱스를 사용하더라도 **배치 I/O 기능이 작동하면 데이터 정렬 순서를 보장할 수 없기 때문에** 옵티마이저가 이런 선택을 한 것이다.

    ```
    SQL> select /*+ batch_table_access_by_rowid(e) */ *
      2  from  emp e
      3  where deptno = 20
      4  order by job, empno;

    ----------------------------------------------------------------------------------
    | Id  | Operation                              | Name    | Rows  | Bytes | Cost  |
    ----------------------------------------------------------------------------------
    |   0 | SELECT STATEMENT                       |         |     5 |   190 |     2 |
    |   1 |   SORT ORDER BY                        |         |     5 |   190 |     2 |
    |   2 |     TABLE ACCESS BY INDEX ROWID BATCHED| EMP     |     5 |   190 |     2 |
    |   3 |       INDEX RANGE SCAN                 | EMP_X01 |     5 |       |     1 |
    ----------------------------------------------------------------------------------
    ```
    애초에 인덱스로 소트 연산을 생략할 수 없거나 SQL에 ORDER BY가 없으면, 랜덤 I/O 성능을 향상하는 이 좋은 기능을 사용하지 않을 이유가 없다.
    그럴 때 옵티마이저는 기본적으로 배치 I/O를 선택한다.

    배치 I/O를 통해 얻을 수 있는 성능 이점이 많음에도 불구하고 시스템 레벨에서 이를 비활성화하는 경우가 종종 있다. (_optimizer_batch_table_access_by_rowid 파마미터를 false로 설정)
    이 기능을 비활성화하는 이유는 '필요한' ORDER BY를 생략한 SQL 패턴 때문이다.
    SQL에 ORDER BY가 없으면 결과집합의 정렬 순서를 보장할 필요가 없으므로 옵티마이저가 배치 I/O를 선택할 수 있고, 출력된 결과집합의 정렬 순서가 매번 다를 수 있다.

    '필요한' ORDER BY를 생략한 SQL 패턴은 아래와 같은 경우를 말한다.
    ```
    -- 상태변경이력_PK : 장비번호 + 변경일시
    SELECT /*+ INDEX(H 상태변경이력_PK) */ 장비번호, 변경일시, 상태코드
    FROM   상태변경이력 H
    WHERE  장비번호 = :eqp_no
    AND    ROWNUM <= 10;        -- 변경일시 순으로 상위 10개 레코드 출력

    SELECT 장비번호, 장비명, 상태코드
        , (SELECT /*+ INDEX(H 상태변경이력_PK) */ 변경일시
           FROM   상태변경이력 H
           WHERE  장비번호 = P.장비번호
           AND    ROWNUM <= 1) 최종변경일시  -- 변경일시 역순으로 상위 1개 레코드 조회
    FROM   장비
    WHERE  장비구분코드 = 'A001';
    ```
    인덱스를 이용하면 결과집합이 자동으로 인덱스 키값 순으로 정렬되므로 ORDER BY를 생략한 채 rownum 조건과 함께 index/index_desc 힌트를 사용하는 패턴을 과거에 많이 사용했었다.
    부분범위 처리 효과를 얻기 위해 rownum 조차 없이 index 힌트만으로 아래와 같이 쿼리를 작성하기도 했다.

    ```
    SELECT /*+ INDEX(H 상태변경이력_PK) */ 장비번호, 변경일시, 상태코드
    FROM   상태변경이력 H
    WHERE  장비번호 = :eqp_no ;
    ```
    오라클 기능이 개선되면서 굳이 이 패턴을 써야 할 이유가 없어진 지 오래됐지만, 결과집합의 정렬 순서가 보장됐기 때문이다.
    하지만, 12c로 업그레이드하면 정렬 순서가 달라질 수 있으므로 이 패턴은 반드시 수정해야 한다.
    no_batch_table_access_by_rowid 힌트를 사용해도 되지만, 할 수 있다면 ORDER BY를 추가하는 것이 바람직하다.

    안타까운 것은, 전반적으로 위와 같은 패턴을 많이 사용해 온 시스템들은 12c로 업그레이드할 때 이 기능을 비활성화하는 쪽으로 결정한다는 사실이다.
    이제 인덱스 정렬 순서를 믿고 ORDER BY를 생략하는 개발 패턴은 사용하지 않아야 한다.

    참고로, 12c에 도입된 일반 배치 I/O와 NL 조인에 작동하는 기존 배치 I/O는 파라미터, 힌트, 실행계획 표현방식이 모두 다르다.