# 1.3 | 데이터 저장 구조 및 I/O 메커니즘
I/O 튜닝이 곧 SQL 튜닝이라고 해도 과언이 아니다. SQL 튜닝 원리를 제대로 이해하려면 I/O에 대한 이해가 중요할 수밖에 없다.
SQL 튜닝을 본격적으로 시작하기에 앞서 데이터 저장 구조, 디스크 및 메모리에서 데이터를 읽는 메커니즘을 차례로 살펴보자.

<br/>

## (1) SQL이 느린 이유
SQL이 느린 이유는 십중팔구 I/O 때문이다. 구체적으로 말해, 디스크 I/O 때문이다.

I/O는 잠(SLEEP)과 같다. OS 또는 I/O 서브시스템이 I/O를 처리하는 동안 프로세스는 잠을 자기 때문이다.
프로세스가 일하지 않고 잠을 자는 이유는 여러 가지가 있지만, I/O가 가장 대표적이고 절대 비중을 차지한다.

프로세스(Process)는 '실행 중인 프로그램'이며, 생명주기를 갖는다. 즉, 생성(new) 이후 종료(terminated) 전까지 준비(ready)와 실행(running)과 대기(waiting) 상태를 반복한다.
실행 중인 프로세스는 interrupt에 의해 수시로 실행 준비 상태(Runnable Queue)로 전환했다가 다시 실행 상태로 전환한다.
여러 프로세스가 하나의 CPU를 공유할 수 있지만, 특정 순간에는 하나의 프로세스만 CPU를 사용할 수 있기 때문에 이런 메커니즘이 필요하다.

interrupt 없이 열심히 일하던 프로세스도 디스크에서 데이터를 읽어야 할 땐 CPU를 OS에 반환하고 잠시 수면(waiting) 상태에서 I/O가 완료되기를 기다린다.
정해진 OS 함수를 호출(I/O Call)하고 CPU를 반환한 채 알람을 설정하고 대기 큐(Wait Queue)에서 잠을 자는 것이다.
열심히 일해야 할 프로세스가 한가하게 잠을 자고 있으니 I/O가 많으면 성능이 느릴 수밖에 없다.

I/O Call 속도는 Single Block I/O 기준으로 평균 10ms쯤 된다. 초당 100 블록쯤 읽는 셈이다. 큰 캐시를 가진 SAN 스토리지는 4 ~ 8ms쯤 된다. 초당 125 ~ 250 블록쯤 읽는 셈이다.
SSD까지 활용하는 최근 스토리지는 1 ~ 2ms, 즉 초당 500 ~ 1,000 블록쯤 읽는다.

스토리지 성능이 빨라지고 있지만, 여전히 우리 기대에는 못 미친다. 어떤 SQL이 Single Block I/O 방식으로 10,000 블록을 읽는다면, 가장 최신 스토리지에서도 10초 이상 기다려야 한다.
전반적으로 I/O 튜닝이 안 된 시스템이라면, 수많은 프로세스에 의해 동시다발적으로 발생하는 I/O Call 때문에 디스크 경합이 심해지고 그만큼 대기 시간도 늘어난다. 10초가 아니라 20초를 기다려야 할 수도 있다는 뜻이다.
SQL이 느린 이유가 바로 여기에 있다 디스크 I/O 때문이다. 디스크 I/O가 SQL 성능을 좌우한다고 해도 과언이 아니다.

I/O 메커니즘을 자세히 설명하기에 앞서 데이터베이스 저장 구조부터 살펴보자.

<br/>

## (2) 데이터베이스 저장 구조
데이터를 저장하려면 먼저 테이블스페이스를 생성해야 한다. 테이블스페이스는 세그먼트를 담는 콘테이너로서, 여러 개의 데이터파일(디스크 상의 물리적인 OS 파일)로 구성된다.

테이블스페이스를 생성했으면 세그먼트를 생성한다. 세그먼트는 테이블, 인덱스처럼 데이터 저장공간이 필요한 오브젝트다. 테이블, 인덱스를 생성할 때 데이터를 어떤 테이블스페이스에 저장할지를 지정한다.

세그먼트는 여러 익스텐트로 구성된다. 파티션 구조가 아니라면 테이블도 하나의 세그먼트요, 인덱스도 하나의 세그먼트다. 테이블 또는 인덱스가 파티션 구조라면, 각 파티션이 하나의 세그먼트가 된다.
LOB 컬럼은 그 자체가 하나의 세그먼트를 구성하므로 자신이 속한 테이블과 다른 별도 공간에 값을 저장한다.

익스텐트는 공간을 확장하는 단위이다. 테이블이나 인덱스에 데이터를 입력하다가 공간이 부족해지면 해당 오브젝트가 속한 테이블스페이스로부터 익스텐트를 추가로 할당받는다.
익스텐트는 연속된 블록들의 집합이기도 하다. 연속된 여러 개의 데이터 블록으로 구성된다.

익스텐트 단위로 공간을 확장하지만, 사용자가 입력한 레코드를 실제로 저장하는 공간은 데이터 블록이다. 참고로, DB2, SQL Server 같은 DBMS는 블록 대신 페이지(page)라는 용어를 사용한다.
한 블록은 하나의 테이블이 독점한다. 즉, 한 블록에 저장된 레코드는 모두 같은 테이블 레코드다.
- 다중 테이블 클러스터일 때는 한 블록에 여러 테이블 레코드가 같이 저장될 수 있다.

한 익스텐트도 하나의 테이블이 독점한다. 즉, 한 익스텐트에 담긴 블록은 모두 같은 테이블 블록이다. 참고로, MS-SQL Server는 한 익스텐트를 여러 오브젝트가 같이 사용할 수도 있다.

테이블스페이스, 세그먼트, 익스텐트, 블록 간 관계뿐만 아니라, 이들과 데이터파일 간의 관계도 알아둘 필요가 있다.

세그먼트 공간이 부족해지면 테이블스페이스로부터 익스텐트를 추가로 할당받는다고 했는데, 세그먼트에 할당된 모든 익스텐트가 같은 데이터파일에 위치하지 않을 수 있다.
아니, 서로 다른 데이터파일에 위치할 가능성이 더 높다. 하나의 테이블스페이스를 여러 데이터파일로 구성하면, 파일 경합을 줄이기 위해 DBMS가 데이터를 가능한 한 여러 데이터파일로 분산해서 저장하기 때문이다.

익스텐트 내 블록은 서로 인접한 연속된 공간이지만, 익스텐트끼리는 연속된 공간이 아니라는 사실을 알 수 있다. 오라클에서 세그먼트에 할당된 익스텐트 목록을 조회하는 방법은 아래와 같다.
```
SQL> select segment_type, tablespace_name, extend_id, file_id, block_id, blocks
  2  from   dba_extents
  3  where  owner = USER
  4  and    segment_name = 'MY_SEGMENT'
  5  order by extent_id;
```
세그먼트를 DBA_EXTENTS 뷰에서 조회하면 다음과 같은 결과를 확인할 수 있다.
```
SEGMENT_TYPE  TABLESPACE_NAME    EXTEND_ID      FILE_ID     BLOCK_ID      BLOCKS
------------  ---------------  -----------  -----------  -----------  -----------
TABLE         USERS                      0            1            1            4
TABLE         USERS                      1            1            9            4
TABLE         USERS                      2            2            1            4
TABLE         USERS                      3            2            5            4
TABLE         USERS                      4            2           13            4
TABLE         USERS                      5            3            1            4
TABLE         USERS                      6            4            9            4
TABLE         USERS                      7            5            5            4
TABLE         USERS                      8            5           17            4
```
이 세그먼트에 할당된 2번 익스텐트는 2번 데이터파일 1번 블록으로부터 연속된 네 개 블록으로 이루어져 있다. 바로 뒤에 할당된 3번 익스텐트는 그래서 5번 블록부터 시작한다.
다른 익스텐트들은 직전 익스텐트와 인접하지 않는다.

- #### [DBA]
  모든 데이터 블록은 디스크 상에서 몇 번 데이터파일의 몇 번째 블록인지를 나타내는 자신만의고유 주소값을 갖는다. 이 주소값을 DBA(Data Block Address)라고 부른다.
  데이터를 읽고 쓰는 단위가 블록이므로 데이터를 읽으려면 먼저 DBA부터 확인해야 한다.

  인덱스를 이용해 테이블 레코드를 읽을 때는 인덱스 ROWID를 이용한다. ROWID는 DBA + 로우 번호(블록 내 순번)로 구성되므로 이를 분해하면 읽어야 할 테이블 레코드가 저장된 DBA를 알 수 있다.

  테이블을 스캔할 때는 테이블 세그먼트 헤더에 저장된 익스텐트 맵을 이용한다. 익스텐트 맵을 통해 각 익스텐트의 첫 번째 블록 DBA를 알 수 있다.
  익스텐트는 연속된 블록 집합이므로 테이블을 스캔할 때는 첫 번째 블록 뒤에 연속해서 저장된 블록을 읽으면 된다.

  블록, 익스텐트, 세그먼트, 테이블스페이스, 데이터파일을 간단히 정의하면, 다음과 같다.
  - 블록 : 데이터를 읽고 쓰는 단위
  - 익스텐트 : 공간을 확장하는 단위, 연속된 블록 집합
  - 세그먼트 : 데이터 저장공간이 필요한 오브젝트(테이블, 인덱스, 파티션, LOB 등)
  - 테이블스페이스 : 세그먼트를 담는 콘테이너
  - 데이터파일 : 디스크 상의 물리적인 OS 파일

<br/>

## (3) 블록 단위 I/O
DBMS는 블록을 단위로 데이터를 읽고 쓴다. 데이터 I/O 단위가 블록이므로 특정 레코드 하나를 읽고 싶어도 해당 블록을 통째로 읽는다.

아래는 오라클 데이터베이스의 블록 사이즈를 확인하는 가장 쉬운 방법이다.
```
SQL> show parameter block_size

NAME                                TYPE          VALUE
----------------------------------  ------------  ------------
db_block_size                       integer       8192
```
아래와 같이 V$PARAMETER 뷰를 직접 조회할 수도 있다.
```
SQL> select value from v$parameter where name = 'db_block_size';

VALUE
----------------------------------
8192

1개의 행이 선택되었습니다.
```

테이블뿐만 아니라 인덱스도 블록 단위로 데이터를 읽고 쓴다.

<br/>

## (4) 시퀀셜 액세스 vs. 랜덤 액세스
테이블 또는 인덱스 블록을 액세스하는(=읽는) 방식으로 시퀀셜 액세스와 랜덤 액세스, 두 가지가 있다.

**시퀀셜(Sequential) 액세스**는 논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방식이다. 인덱스 리프 블록은 앞뒤를 가리키는 주소값을 통해 논리적으로 서로 연결돼 있다.
이 주소 값에 따라 앞 또는 뒤로 순차적으로 스캔하는 방식이 시퀀셜 액세스다.
테이블 블록 간에는 서로 논리적인 연결고리를 갖고 있지 않다. 그럼, 테이블은 어떻게 시퀀셜 방식으로 액세스할까?
오라클은 세그먼트에 할당된 익스텐트 목록을 세그먼트 헤더에 맵(map)으로 관리한다. 익스텐트 맵은 각 익스텐트의 첫 번째 블록 주소 값을 갖는다.(DBA, EXTENTS 뷰 참조)
읽어야 할 익스텐트 목록을 익스텐트 맵에서 얻고, 각 익스텐트의 첫 번째 블록 뒤에 연속해서 저장된 블록을 순서대로 읽으면, 그것이 곧 Full Table Scan이다.

**랜덤(Random) 액세스**는 논리적, 물리적인 순서를 따르지 않고, 레코드 하나를 읽기 위해 한 블록씩 접근(=touch)하는 방식이다.

<br/>

## (5) 논리적 I/O vs. 물리적 I/O

### [DB 버퍼캐시]
다시 강조하지만, 디스크 I/O가 SQL 성능을 결정한다. SQL을 수행하는 과정에 계속해서 데이터 블록을 읽는데, 자주 읽는 블록을 매번 디스크에서 읽는 것은 매우 비효율적이다.
모든 DBMS에 데이터 캐싱 메커니즘이 필수인 이유다.

라이브러리 캐시가 SQL과 실행계획, DB 저장형 함수/프로시저 등을 캐싱하는 '코드 캐시'라고 한다면 DB 버퍼캐시는 '데이터 캐시'라고 할 수 있다.
디스크에서 어렵게 읽은 데이터 블록을 캐싱해 둠으로써 같은 블록에 대한 반복적인 I/O Call을 줄이는 데 목적이 있다.

서버 프로세스와 데이터파일 사이에 버퍼캐시가 있으므로 데이터 블록을 읽을 땐 항상 버퍼캐시부터 탐색한다.
운 좋게 캐시에서 블록을 찾는다면 바쁜 시간에 프로세스가 잠(I/O Call)을 자지 않아도 되니 얼마나 다행인가.
운이 없어 캐시에서 못 찾아도, 한 번은 I/O Call을 하고 잠을 자겠지만, 같은 블록을 두 번째 읽을 때부터는 잠을 자지 않아도 된다.
버퍼캐시는 공유메모리 영역이므로 같은 블록을 읽는 다른 프로세스도 득을 본다.

아래는 오라클 SQL*Plus에서 버퍼캐시 사이즈를 확인하는 가장 쉬운 방법이다. SQL*Plus로 접속하지 않았다면, V$SGA 뷰를 통해 확인할 수 있다.
```
SQL> show sga

Total System Global Area 3390558208 bytes
Fixed Size                  2180464 bytes
Variable Size            1996491408 bytes
Database Buffers         1375731712 bytes
Redo Buffers               16154624 bytes
```

### [논리적 I/O vs. 물리적 I/O]
논리적 블록 I/O는 SQL을 처리하는 과정에 발생한 총 블록 I/O를 말한다. 일반적으로 메모리상의 버퍼 캐시를 경유하므로 메모리 I/O가 곧 논리적 I/O라고 생각해도 무방하다.
(메모리를 경유하지 않는 Direct Path I/O를 고려하면, 논리적 I/O는 메모리 I/O와 Direct Path I/O를 더한 개념이다.)

물리적 블록 I/O는 디스크에서 발생한 총 블록 I/O를 말한다. SQL 처리 도중 읽어야 할 블록을 버퍼캐시에서 찾지 못할 때만 디스크를 액세스하므로 논리적 블록 I/O 중 일부를 물리적으로 I/O 한다.

메모리 I/O는 전기적 신호인 데 반해, 디스크 I/O는 액세스 암(Arm)을 통해 물리적 작용이 일어나므로 메모리 I/O에 비해 상당히 느리다. 보통, 10,000배쯤 느리다.
디스크 경합이 심할 때는 더 느리다.

### [왜 논리적 I/O인가?]
데이터베이스 세계에서 논리적 일량과 물리적 일량을 정의해 보자. SQL을 수행하려면 데이터가 담긴 블록을 읽어야 한다.
SQL이 참조하는 테이블에 데이터를 입력하거나 삭제하지 않는 상황에서 조건절에 같은 변수 값을 입력하면, 아무리 여러 번 실행해도 매번 읽는 블록 수는 같다.
SQL을 수행하면서 읽은 총 블록 I/O가 논리적 I/O다.

Direct Path Read 방식으로 읽는 경우를 제외하면 모든 블록은 DB 버퍼캐시를 경유해서 읽는다. 따라서 논리적 I/O 횟수는 일반적으로 DB 버퍼캐시에서 블록을 읽은 횟수와 일치한다.
논리적 I/O가 메모리 I/O와 같은 개념은 아니지만, 결과적으로 수치는 같다.
- 디스크 소트 과정에서 소트 Runs로부터 블록을 읽거나 병렬 쿼리로 Full Scan을 수행할 때 Direct Path Read 방식을 사용한다.<br/>([6.2] 'Direct Path I/O 활용' 참고)

DB 버퍼캐시에서 블록을 찾지 못해 디스크에서 읽은 블록 I/O가 물리적 I/O다. 데이터 입력이나 삭제가 없어도 물리적 I/O는 SQL을 실행할 때마다 다르다.
첫 번째 실행할 때보다 두 번째 실행할 때 줄어들고, 세 번째 실행할 땐 더 줄어든다. 연속해서 실행하면 DB 버퍼캐시에서 해당 테이블 블록의 점유율이 점점 높아지기 때문이다.
한참 후에 다시 실행하면 반대로 물리적 I/O가 늘어난다. DB 버퍼캐시가 다른 테이블 블록으로 채워지기 때문이다.

- #### [블록 I/O 적정량]
  강의 중에 "SQL마다 블록 I/O 적정량은 얼마인가"라는 질문을 받았다. OLTP성 업무 기준으로 몇 개일까? DW성 업무 기준으로는 몇 개일까? 배치 프로그램에서는?

  SQL을 수행하는 데 필요한 논리적 일량은 모두 다르다. 아무리 최적화해도 해당 SQL이 하고자 하는 일이 무엇이냐에 따라 블록 I/O 발생량은 천차만별이다.
  검색 범위, 조인하는 테이블 개수, 대상 테이블의 크기, 인덱스 구조 등에 의해 결정된다.

### [버퍼 캐시 히트율]
버퍼캐시 효율을 측정하는 데 전통적으로 가장 많이 사용해 온 지표는 버퍼캐시 히트율(Buffer Cache Hit Ratio, 이하 'BCHR')이다. 구하는 공식은 아래와 같다.
```
BCHR  = ( 캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수 ) ✕ 100
      = ( (논리적 I/O - 물리적 I/O) / 논리적 I/O ) ✕ 100
      = ( 1 - (물리적 I/O) / (논리적 I/O) ) ✕ 100
```
공식에서 알 수 있듯 BCHR은 읽은 전체 블록 중에서 물리적인 디스크 I/O를 수반하지 않고 곧바로 메모리에서 찾은 비율을 나타낸다.

애플리케이션 특성에 따라 다르지만, 온라인 트랜잭션을 주로 처리하는 애플리케이션이라면 시스템 레벨에서 평균 99% 히트율을 달성해야 한다.
핵심 트랜잭션이 시스템 전체 부하의 대부분을 차지하므로 열심히 튜닝하면 99%는 결코 달성하기 어려운 수치가 아니다.

BCHR 공식에서 우리는 중요한 성능 원리를 발견할 수 있다. 물리적 I/O가 성능을 결정하지만, 실제 SQL 성능을 향상하려면 물리적 I/O가 아닌 논리적 I/O를 줄여야 한다는 사실이다.
BCHR 공식을 아래와 같이 변형하면, 쉽게 알 수 있다.
- 물리적 I/O = 논리적 I/O ✕ (100% - BCHR)

논리적 I/O는 일정하므로 물리적 I/O는 BCHR에 의해 결정된다.(데이터를 입력/수정/삭제하지 않는 상황에서 조건절에 같은 변수 값을 입력하면, 논리적 I/O는 항상 같다.)
BCHR은 시스템 상황에 따라 달라지므로 물리적 I/O는 결국 시스템 상황에 의해 결정되는 통제 불가능한 외생변수다.
- 물리적 I/O가 SQL 성능을 좌우한다고 했는데, BCHR이 SQL 성능을 좌우한다고도 해석할 수 있다.

SQL 성능을 높이기 위해서 할 수 있는 일은 논리적 I/O를 줄이는 일뿐이다.
예를 들어, 시스템 레벨 BCHR이 평균 70%라고 할 때, 특정 SQL의 논리적 I/O가 10,000개면 물리적 I/O는 대략 3,000개쯤 발생할 것으로 예상할 수 있다/
- 물리적 I/O = 논리적 I/O ✕ (100 - 70)% = 10,000 ✕ 30% = 3,000

논리적 I/O를 1,000개로 줄이면 물리적 I/O도 300으로 감소하고, 성능도 열 배 향상된다/
- 물리적 I/O = 1,000 ✕ 30% = 300

그럼, 논리적 I/O는 어떻게 줄일 수 있을까? SQL을 튜닝해서 읽는 총 블록 개수를 줄이면 된다. 논리적 I/O는 항상 일정하게 발생하지만, SQL 튜닝을 통해 줄일 수 있는 통제 가능한 내생변수다.
**논리적 I/O를 줄임으로써 물리적 I/O를 줄이는 것이 곧 SQL 튜닝이다.**

요약하면, BCHR 공식을 이루는 물리적 I/O는 통제 불가능한 외생변수다. (메모리를 증설해서 DB 버퍼캐시 크기를 늘리는 방법 외에) 이것을 직접 줄일 방법은 없다.
반면, 논리적 I/O는 통제 가능한 내생변수다. SQL을 튜닝해서 논리적 I/O를 줄이면 물리적 I/O도 줄고, 그만큼 성능도 향상된다.

BCHR을 실제로 계산해 보자. 아래는 SQL 트레이스를 통해 수집한 Call 통계 정보다.
Query와 Current 항목을 더한 값이 논리적 I/O, 즉 SQL 수행 과정에 읽은 (일반적으로 DB 버퍼캐시에서 읽은) 총 블록 개수다.
Disk 항목은 디스크에서 물리적으로 읽은 블록 개수다.
- 오라클에서 SELECT문은 Consistent 모드로 블록을 읽는다. DML문은 Consistent 모드로 블록을 읽고, Current 모드로 블록을 다시 읽어서 갱신한다.
  Query 항목은 Consistent 모드로 읽은 블록 수, Current 항목은 Current 모드로 읽은 블록 수를 의미한다.

```
Call    Count CPU Time Elapsed Time      Disk      Query    Current      Rows
------ ------ -------- ------------ --------- ---------- ---------- ----------
Parse       1    0.000        0.001         0          0          0          0
Execute     1    0.010        0.006         0          0          0          0
Fetch       2  138.680     1746.630    601458    1351677      12367          1
------ ------ -------- ------------ --------- ---------- ---------- ----------
Total       4  138.690     1746.637    601458    1351677      12367          1
```

위 트레이스 결과를 놓고 디스크에서 601,458개, 버퍼캐시에서 1,364,044(=1,351,677+12,367)개 블록을 읽었으므로 논리적 I/O는 총 1,965,502개라고 잘못 해석하는 분이 있을 것이다.

다시 말하지만, 블록을 읽을 때는 해당 블록을 먼저 버퍼캐시에서 찾아보고 없을 때만 디스크에서 읽는다. 이때도 **디스크에서 곧바로 읽는 게 아니라 먼저 버퍼캐시에서 적재하고서 읽는다.**
따라서 DB 버퍼캐시에서 읽은 1,364,044개 블록에는 디스크에서 읽은 601,458개 블록이 이미 포함돼 있다.

SQL 수행 과정에 총 1,364,044개 블록을 읽었고, 그중 601,458개를 디스크에서 읽었으므로 BCHR은 다음과 같다.
- BCHR = (1 - (Disk / (Query + Current))) ✕ 100
  = (1 - (601,458 / (1,351,677 + 12,367))) ✕ 100
  = 55.9%

BCHR에는 주의해야 할 함정이 있다. BCHR이 SQL 성능을 좌우하지만, **BCHR이 높다고 해서 효율적인 SQL을 의미하지 않는다**는 사실이다.
같은 블록을 비효율적으로 반복해서 읽으면 BCHR이 높아진다.

<br/>

## (6) Single Block I/O vs. Multiblock I/O
메모리 캐시가 클수록 좋지만, 데이터를 모두 캐시에 적재할 수는 없다. 비용적인 한계, 기술적인 한계 때문에 전체 데이터 중 일부만 캐시에 적재해서 읽을 수 있다.

캐시에서 찾지 못한 데이터 블록은 I/O Call을 통해 디스크에서 DB 버퍼캐시로 적재하고서 읽는다. I/O Call 할 때, 한 번에 한 블록씩 요청하기도 하고, 여러 블록씩 요청하기도 한다.
한 번에 한 블록씩 요청해서 메모리에 적재하는 방식을 'Single Block I/O'라고 한다.
많은 벽돌을 실어 나를 때 손수레를 이용하는 것처럼 한 번에 여러 블록씩 요청해서 메모리에 적재하는 방식을 'Multiblcok I/O'라고 한다.

인덱스를 이용할 떄는 기본적으로 인덱스와 테이블 블록 모두 Single Block I/O 방식을 사용한다. 구체적으로 아래 목록이 Single Block I/O 대상 오퍼레이션이다.
인덱스는 소량 데이터를 읽을 때 주로 사용하므로 이 방식이 효율적이다.
- 인덱스 루트 블록을 읽을 때
- 인덱스 루트 블록에서 얻은 주소 정보로 브랜치 블록을 읽을 때
- 인덱스 브랜치 블록에서 얻은 주소 정보로 리프 블록을 읽을 때
- 인덱스 리프 블록에서 얻은 주소 정보로 테이블 블록을 읽을 때

반대로, 많은 데이터 블록을 읽을 때는 Multiblcok I/O 방식이 효율적이다. 그래서 인덱스를 이용하지 않고 테이블 전체를 스캔할 때 이 방식을 사용한다.
테이블이 클수록 Multiblock I/O 단위도 크면 좋다. 이유는 다른 데 있지 않다. 프로세스가 잠자는 횟수를 줄여주는 데 있다.

읽고자 하는 블록을 DB 버퍼캐시에서 찾지 못하면 해당 블록을 디스크에서 읽기 위해 I/O Call을 한다. 그동안 프로세스는 대기 큐(Wait Queue)에서 잠을 잔다.
대용량 테이블이면 수많은 블록을 디스크에서 읽는 동안 여러 차례 잠을 잘 텐데, 기왕에 잠을 자려면 한꺼번에 많은 양을 요청해야 잠자는 횟수를 줄이고 성능을 높일 수 있다.
대용량 테이블을 Full Scan할 때 Multiblock I/O 단위를 크게 설정하면 성능이 좋아지는 이유다.

정리하면, Multiblock I/O는 캐시에서 찾지 못한 특정 블록을 읽으려고 I/O Call 할 때 디스크 상에 그 블록과 '인접한' 블록들을 한꺼번에 읽어 캐시에 미리 적재하는 기능이다.
DBMS 블록 사이즈가 얼마건 간에 OS 단에서는 보통 1MB 단위로 I/O를 수행한다(OS마다 다름).

오라클에서 손수레에 한 번에 담는 양은 db_file_multiblock_read_count 파라미터로 정한다.
```
SQL> show parameter db_file_multiblock_read_count

NAME                                TYPE         VALUE
----------------------------------  -----------  -----------
db_file_multiblock_read_count       integer       16

SQL> alter session set db_file_multiblock_read_count = 128;

세션이 변경되었습니다.
```
일반적으로 OS 레벨 I/O 단위가 1MB, 오라클 레벨 I/O 단위가 8KB이므로 이 파라미터를 128로 설정하면 담을 수 있는 만큼 최대한 담게 된다(8KB ✕ 128 = 1MB).
손수레에는 어차피 1MB 이상 담을 수 없으므로 그 이상으로 설정해도 소용없다. 오라클 레벨에서 그렇게 설정할 순 있지만, OS는 자신의 I/O 단위만큼씩만 읽는다.

조금 더 부연해 설명하면, '인접한 블록'이란 같은 익스텐트에 속한 블록을 의미한다. Multiblock I/O 방식으로 읽더라도 익스텐트 경계를 넘지 못한다는 뜻이다.
예를 들어, 한 익스텐트에 20개 블록이 담겨있고 Multiblock I/O 단위가 8이라고 할 때, 세 번째 I/O Call에서는 네 개 블록만 얻게 된다. 이때 네 개를 더 읽기 위해 다음 익스텐트까지 읽지 않는다.

- #### [Multiblock I/O 중간에 왜 Single Block I/O가 나타나는가?]
  가장 많이 받는 질문 중 하나다. 이 질문에 대한 해답을 얻으려면 (1) '익스텐트 맵'은 테이블 블록에 대한 인덱스, (2) 'Multiblock I/O'는 배치(Batch) I/O라고 생각하면 쉽다.

  Multiblock I/O 단위는 4라고 가정하자.
  익스텐트 맵을 통해 첫 번째 익스텐트에서 읽어야 할 블록 목록을 확인하니 1,2,3,4,5,6,7,8,9,10이었고, 그중 1번, 6번, 8번 블록이 현재 버퍼캐시에 캐싱 돼 있다고 가정하자.
  - 1번을 캐시버퍼 체인에서 찾았다. 1번 버퍼블록을 캐시에서 바로 읽는다.
  - 2번을 캐시버퍼 체인에서 못 찾았다. 디스크 I/O를 보류한다.
  - 3번을 캐시버퍼 체인에서 못 찾았다. 디스크 I/O를 보류한다.
  - 4번을 캐시버퍼 체인에서 못 찾았다. 디스크 I/O를 보류한다.
  - 5번을 캐시버퍼 체인에서 못 찾았다. 2~5번 블록을 위해 Multiblock I/O 방식으로 디스크 I/O Call 한다. 2~5번 버퍼블록을 캐시에서 읽는다.
  - 6번을 캐시버퍼 체인에서 찾았다. 6번 버퍼블록을 캐시에서 바로 읽는다.
  - 7번을 캐시버퍼 체인에서 못 찾았다. 디스크 I/O를 보류한다.
  - 8번을 캐시버퍼 체인에서 찾았다. 7번 블록을 위해 Single Block I/O 방식으로 디스크 I/O Call한다. 7~8번 버퍼블록을 캐시에서 읽는다.
  - 9번을 캐시버퍼 체인에서 못 찾았다. 디스크 I/O를 보류한다.
  - 10번을 캐시버퍼 체인에서 못 찾았따. 익스텐트 마지막 블록이므로 9~10번 블록을 위해 Multiblock I/O 방식으로 디스크 I/O Call 한다. 9~10번 버퍼블록을 캐시에서 읽는다.

  1,6,8번 뿐만 아니라 9번 블록도 캐싱 돼 있었다고 하자. 그러면 9번 블록은 캐시버퍼에서 읽고, 10번 블록은 익스텐트 마지막 블록이므로 바로 Single Block I/O 방식으로 디스크 I/O Call 한다.

  마지막으로, Full Scan 중에 Chain이 발생한 로우를 읽을 때도 Single Block I/O 방식으로 디스크 블록을 읽는다.

<br/>

## (7) Table Full Scan vs. Index Range Scan
테이블에 저장된 데이터를 읽는 방식은 두 가지다. 테이블 전체를 스캔해서 읽는 방식과 인덱스를 사용해서 읽는 방식이다.
전자를 'Table Full Scan'이라고 부른다는 것은 주지의 사실이다. 후자는, 제목에 'Index Range Scan'이라고 간략히 표현했지만, 보통 '인덱스를 이용한 테이블 액세스'라고 표현한다.

Table Full Scan은 말 그대로 테이블에 속한 블록 '전체'를 읽어서 사용자가 원하는 데이터를 찾는 방식이다.
인덱스를 이용한 테이블 액세스는 인덱스에서 '일정량'을 스캔하면서 얻은 ROWID로 테이블 레코드를 찾아가는 방식이다. ROWID는 테이블 레코드가 디스크 상에 어디 저장됐는지를 가리키는 위치 정보다.

인덱스를 이용해 많은 데이터를 읽을 때 왜 성능이 느려질까?

Table Full Scan은 시퀀셜 액세스와 Multiblock I/O 방식으로 디스크 블록을 읽는다.
한 블록에 속한 모든 레코드를 한 번에 읽어 들이고, 캐시에서 못 찾으면 '한 번의 수면(I/O Call)을 통해 인접한 수십~수백 개 블록을 한꺼번에 I/O하는 메커니즘이다.
이 방식을 사용하는 SQL은 스토리지 스캔 성능이 좋아지는 만큼 성능도 좋아진다.

시퀀셜 액세스와 Multiblock I/O가 아무리 좋아도 수십~수백 건의 소량 데이터 찾을 때 수백만~수천만 건 데이터를 스캔하는 건 비효율적이다.
큰 테이블에서 소량 데이터를 검색할 때는 반드시 인덱스를 이용해야 한다.

Index Range Scan을 통한 테이블 액세스는 랜덤 액세스와 Single Block I/O 방식으로 디스크 블록을 읽는다.
캐시에서 블록을 못 찾으면, '레코드 하나를 읽기 위해 매번 잠을 자는 I/O 메커니즘'이다. 따라서 많은 데이터를 읽을 때는 Table Full Scan보다 불리하다.
이 방식을 이용하는 SQL은 스토리지 스캔 성능이 수십 배 좋아져도 성능이 조금 밖에 좋아지지 않는다.

게다가 이 방식은 읽었던 블록을 반복해서 읽는 비효율이 있다. 많은 데이터를 읽을 때 물리적인 블록 I/O 뿐만 아니라 논리적인 블록 I/O 측면에서도 불리하다는 얘기다.
각 블록을 단 한 번 읽는 Table Full Scan보다 훨씬 불리하다.

데이터베이스를 효과적으로 이용하는 데 있어 인덱스의 중요성은 아무리 강조해도 지나치지 않다. 하지만, 인덱스에 대한 맹신은 금물이다.
인덱스가 항상 옳은 것은 아니며, 바꿔 말해 Table Full Scan이 항상 나쁜 것도 아니다.
인덱스는 큰 테이블에서 아주 적은 일부 데이터를 빨리 찾기 위한 도구일 뿐이므로 모든 성능 문제를 인덱스로 해결하려 해선 안 된다. 읽을 데이터가 일정량을 넘으면 인덱스보다 Table Full Scan이 유리하다.

<br/>

## (8) 캐시 탐색 메커니즘
Direct Path I/O를 제외한 모든 블록 I/O는 메모리 버퍼캐시를 경유한다. 구체적으로, 아래 오퍼레이션은 모두 버퍼캐시 탐색 과정을 거친다.
- 인덱스 루트 블록을 읽을 때
  - 인덱스 루트 블록 주소는 SQL을 파싱하고 최적화하는 시점에 SQL 커서에 담긴다.
- 인덱스 루트 블록에서 얻은 주소 정보로 브랜치 블록을 읽을 때
- 인덱스 브랜치 블록에서 얻은 주소 정보로 리프 블록을 읽을 때
- 인덱스 리프 블록에서 얻은 주소 정보로 테이블 블록을 읽을 때
- 테이블 블록을 Full Scan 할 때
  - Table Full Scan 할 때는 읽어야 할 블록 목록을 익스텐트 맵(map)에서 얻는다. DBA_EXTENTS 뷰를 참조하기 바란다.

버퍼캐시 탐색 메커니즘을 설명하기에 앞서 버퍼캐시 구조부터 살펴보자. DBMS는 버퍼캐시를 해시 구조로 관리한다.
버퍼캐시에서 블록을 찾을 때 해시 알고리즘으로 버퍼 헤더를 찾고, 거기서 얻은 포인터(Pointer)로 버퍼 블록을 액세스하는 방식을 사용한다. 해시 구조의 특징을 요약하면, 다음과 같다.
- 같은 입력 값은 항상 동일한 해시 체인(=버킷)에 연결됨
- 다른 입력 값이 동일한 해시 체인(=버킷)에 연결될 수 있음
- 해시 체인 내에서는 정렬이 보장되지 않음

### [메모리 공유자원에 대한 액세스 직렬화]
버퍼캐시는 SGA 구성요소이므로 버퍼캐시에 캐싱된 버퍼블록은 모두 공유자원이다. 공유자원은 말 그대로 모두에게 권한이 있기 때문에 누구나 접근할 수 있다.
문제는 하나의 버퍼블록을 두 개 이상 프로세스가 '동시에' 접근하려고 할 때 발생한다. 동시에 접근하면 블록 정합성에 문제가 생길 수 있기 때문이다.

따라서 자원을 공유하는 것처럼 보여도 내부에선 한 프로세스씩 순차적으로 접근하도록 구현해야 하며, 이를 위해 직렬화(serialization) 메커니즘이 필요하다. 직렬화를 이해하기 쉽게 표현하면, '줄 세우기'다.
같이 사용하는 것처럼 보이지만, 특정 순간에는 한 프로세스만 사용할 수 있다. 그 순간 다른 프로세스는 줄 서서 기다려야 한다. 이런 줄서기가 가능하도록 지원하는 메커니즘이 래치(Latch)이다.
- #### [캐시버퍼 체인 래치]
  대량의 데이터를 읽을 때 모든 블록에 대해 해시 체인을 탐색한다. DBA(Data Block Address)를 해시 함수에 입력하고 거기서 반환된 값으로 스캔해야 할 해시 체인을 찾는다.
  해시 체인을 스캔하는 동안 다른 프로세스가 체인 구조를 변경하는 일이 생기면 곤란하다. 이를 막기 위해 해시 체인 래치가 존재한다. 이 자물쇠를 열 수 있는 키(Key)를 획득한 프로세스만이 체인으로 진입 가능하다.

SGA를 구성하는 서브 캐시마다 별도의 래치가 존재하는데, 버퍼캐시에는 캐시버퍼 체인 래치, 캐시버퍼 LRU 체인 래치 등이 작동한다.
빠른 데이터베이스를 구현하려면 버퍼캐시 히트율을 높여야 하지만, 캐시 I/O도 생각만큼 빠르지 않을 수 있다. 이들 래치에 의한 경합이 생길 수 있기 때문이다.

캐시버퍼 체인뿐만 아니라 버퍼블록 자체에도 직렬화 메커니즘이 존재한다. 바로 '버퍼 Lock'이다.
이런 직렬화 메커니즘에 의한 캐시 경합을 줄이려면, SQL 튜닝을 통해 쿼리 일량(논리적 I/O) 자체를 줄여야 한다.
- #### [버퍼 Lock]
  읽고자 하는 블록을 찾았으면 캐시버퍼 체인 래치를 곧바로 해제해야 한다. 그래야 해당 래치가 풀리기를 기다렸던 다른 프로세스들이 작업을 재개할 수 있다.

  그런데 래치를 해제한 상태로 버퍼블록 데이터를 읽고 쓰는 도중에 후행 프로세스가 하필 같은 블록에 접근해서 데이터를 읽고 쓴다면 데이터 정합성에 문제가 생길 수 있다.
  이를 방지하기 위해 오라클은 버퍼 Lock을 사용한다. 캐시버퍼 체인 래치를 해제하기 전에 버퍼 헤더에 Lock을 설정함으로써 버퍼블록 자체에 대한 직렬화 문제를 해결하는 것이다.
  (같은 로우는 로우 Lock에 의해 보호될 텐데 버퍼 Lock이 왜 필요할까 싶겠지만, 로우 Lock을 설정하는 행위도 블록을 변경하는 작업이다.
  로우 Lock을 설정하는 순간 다른 프로세스가 해당 블록을 읽는다면 문제가 생긴다. 그뿐만 아니라 같은 블록에서 서로 다른 로우를 동시에 읽고 쓰는 경우를 막기 위해서도 버퍼 Lock은 필요하다.)